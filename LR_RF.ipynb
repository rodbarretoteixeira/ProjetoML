{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b73e9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import randint, uniform\n",
    "import functionsML as f\n",
    "from sklearn.model_selection import train_test_split, PredefinedSplit, RandomizedSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, BaggingRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4b182c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função de Limpeza Básica (Sem Leakage)\n",
    "def clean_data(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Drop irrelevant\n",
    "    df = df.drop(columns=[\"hasDamage\",\"paintQuality%\"], errors='ignore')\n",
    "    \n",
    "    # Text handling\n",
    "    text_cols = df.select_dtypes(include=[\"object\"]).columns\n",
    "    df[text_cols] = df[text_cols].apply(lambda x: x.str.lower() if x.dtype==\"object\" else x)\n",
    "    for col in df.select_dtypes(include=\"object\").columns:\n",
    "        df = f.fix_typos(col, df)\n",
    "\n",
    "    # Transmission: 'other' passa a 'unknown'\n",
    "    df['transmission'] = df['transmission'].replace('other', 'unknown')\n",
    "    \n",
    "    # FuelType: 'other' passa a 'electric' (conforme o teu código antigo)\n",
    "    df['fuelType'] = df['fuelType'].replace('other', 'electric')\n",
    "\n",
    "    # Filtering / Cleaning Rules\n",
    "    df.loc[df[\"mileage\"] < 0, \"mileage\"] = np.nan\n",
    "    df.loc[~df[\"tax\"].between(0, 600), \"tax\"] = np.nan\n",
    "    df.loc[~df[\"mpg\"].between(0, 150), \"mpg\"] = np.nan\n",
    "    df.loc[~df[\"engineSize\"].between(1, 6.3), \"engineSize\"] = np.nan\n",
    "    df.loc[~df[\"year\"].between(1990, 2020), \"year\"] = np.nan\n",
    "    df.loc[~df[\"previousOwners\"].between(0, 6), \"previousOwners\"] = np.nan # Opcional conforme o teu código\n",
    "\n",
    "    # Numeric Transformations\n",
    "    df['mileage'] = np.log1p(df['mileage'])\n",
    "    df['mpg'] = np.log1p(df['mpg'])\n",
    "    df['tax'] = np.log1p(df['tax'])\n",
    "    \n",
    "    # Types and Rounding\n",
    "    df[\"year\"] = df[\"year\"].round()\n",
    "    df[\"previousOwners\"] = pd.to_numeric(df[\"previousOwners\"], errors='coerce').round().astype(\"Int64\")\n",
    "    df[\"year\"] = pd.to_numeric(df[\"year\"], errors='coerce').round().astype(\"Int64\")\n",
    "    \n",
    "    # Imputation\n",
    "    df = f.fill_NaN_with_categorical(df, \"Brand\", [\"model\",\"transmission\",\"fuelType\"])\n",
    "    df = f.fill_NaN_with_categorical(df, \"Brand\", [\"model\",\"transmission\"])\n",
    "    df = f.fill_NaN_with_categorical(df, \"model\", [\"Brand\",\"transmission\",\"fuelType\"])\n",
    "    df = f.fill_NaN_with_categorical(df, \"model\", [\"Brand\",\"transmission\"])\n",
    "    df = f.fill_NaN_with_categorical(df, \"mpg\", [\"model\",\"fuelType\"])\n",
    "    \n",
    "    df[\"transmission\"] = df[\"transmission\"].transform(lambda x: x.fillna(x.mode()[0] if not x.mode().empty else np.nan))\n",
    "    df[\"fuelType\"] = df[\"fuelType\"].transform(lambda x: x.fillna(x.mode()[0] if not x.mode().empty else np.nan))\n",
    "\n",
    "    df = f.fill_NaN_with_mixed(df, \"year\", \"model\", \"mileage\")\n",
    "    df = f.fill_NaN_with_mixed(df, \"mileage\", \"model\", \"year\")\n",
    "    df = f.fill_NaN_with_mixed(df, \"tax\", \"model\", \"year\")\n",
    "    df = f.fill_NaN_with_mixed(df, \"engineSize\", \"model\", \"tax\")\n",
    "\n",
    "    df[\"previousOwners\"] = df[\"previousOwners\"].transform(lambda x: x.fillna(x.median())).round().astype(\"Int64\")\n",
    "    \n",
    "    # Residual Fill\n",
    "    numeric_cols = df.select_dtypes(include=[\"number\"]).columns.drop([\"carID\", \"price\"], errors='ignore')\n",
    "    for col in numeric_cols:\n",
    "        df[col] = df[col].astype(float)\n",
    "        global_mean = df[col].median()\n",
    "        df[col] = df[col].fillna(global_mean)\n",
    "        if \"Int64\" in str(df[col].dtype):\n",
    "            df[col] = df[col].round().astype(\"Int64\")\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "765fde63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Drop irrelevant\n",
    "    df = df.drop(columns=[\"hasDamage\",\"paintQuality%\"], errors='ignore')\n",
    "    \n",
    "    # Text handling\n",
    "    text_cols = df.select_dtypes(include=[\"object\"]).columns\n",
    "    df[text_cols] = df[text_cols].apply(lambda x: x.str.lower() if x.dtype==\"object\" else x)\n",
    "    for col in df.select_dtypes(include=\"object\").columns:\n",
    "        df = f.fix_typos(col, df)\n",
    "\n",
    "    # Transmission: 'other' passa a 'unknown'\n",
    "    df['transmission'] = df['transmission'].replace('other', 'unknown')\n",
    "    \n",
    "    # FuelType: 'other' passa a 'electric' (conforme o teu cÃ³digo antigo)\n",
    "    df['fuelType'] = df['fuelType'].replace('other', 'electric')\n",
    "\n",
    "    # Filtering / Cleaning Rules\n",
    "    df.loc[df[\"mileage\"] < 0, \"mileage\"] = np.nan\n",
    "    df.loc[~df[\"tax\"].between(0, 600), \"tax\"] = np.nan\n",
    "    df.loc[~df[\"mpg\"].between(0, 150), \"mpg\"] = np.nan\n",
    "    df.loc[~df[\"engineSize\"].between(1, 6.3), \"engineSize\"] = np.nan\n",
    "    df.loc[~df[\"year\"].between(1990, 2020), \"year\"] = np.nan\n",
    "    df.loc[~df[\"previousOwners\"].between(0, 6), \"previousOwners\"] = np.nan\n",
    "    mask = (df['year'] % 1 != 0)\n",
    "    df.loc[mask, 'year'] = np.nan\n",
    "    mask = (df['mileage'] % 1 != 0)\n",
    "    df.loc[mask, 'mileage'] = np.nan\n",
    "    mask = (df['tax'] % 1 != 0)\n",
    "    df.loc[mask, 'tax'] = np.nan\n",
    "    mask = df['mpg'] != df['mpg'].round(1)\n",
    "    df.loc[mask, 'mpg'] = np.nan\n",
    "    mask = df['engineSize'] != df['engineSize'].round(1)\n",
    "    df.loc[mask, 'engineSize'] = np.nan\n",
    "\n",
    "    # Numeric Transformations\n",
    "    df['mileage'] = np.log1p(df['mileage'])\n",
    "    df['mpg'] = np.log1p(df['mpg'])\n",
    "    df['tax'] = np.log1p(df['tax'])\n",
    "    \n",
    "    # Types and Rounding\n",
    "    df[\"previousOwners\"] = pd.to_numeric(df[\"previousOwners\"], errors='coerce').round().astype(\"Int64\")\n",
    "    df[\"year\"] = pd.to_numeric(df[\"year\"], errors='coerce').round().astype(\"Int64\")\n",
    "    \n",
    "    # Imputation\n",
    "    df = f.fill_NaN_with_categorical(df, \"Brand\", [\"model\",\"transmission\",\"fuelType\"])\n",
    "    df = f.fill_NaN_with_categorical(df, \"Brand\", [\"model\",\"transmission\"])\n",
    "    df = f.fill_NaN_with_categorical(df, \"model\", [\"Brand\",\"transmission\",\"fuelType\"])\n",
    "    df = f.fill_NaN_with_categorical(df, \"model\", [\"Brand\",\"transmission\"])\n",
    "    df = f.fill_NaN_with_categorical(df, \"mpg\", [\"model\",\"fuelType\"])\n",
    "    \n",
    "    df[\"transmission\"] = df[\"transmission\"].transform(lambda x: x.fillna(x.mode()[0] if not x.mode().empty else np.nan))\n",
    "    df[\"fuelType\"] = df[\"fuelType\"].transform(lambda x: x.fillna(x.mode()[0] if not x.mode().empty else np.nan))\n",
    "\n",
    "    df = f.fill_NaN_with_mixed(df, \"year\", \"model\", \"mileage\")\n",
    "    df = f.fill_NaN_with_mixed(df, \"mileage\", \"model\", \"year\")\n",
    "    df = f.fill_NaN_with_mixed(df, \"tax\", \"model\", \"year\")\n",
    "    df = f.fill_NaN_with_mixed(df, \"engineSize\", \"model\", \"tax\")\n",
    "\n",
    "    df[\"previousOwners\"] = df[\"previousOwners\"].transform(lambda x: x.fillna(x.median())).round().astype(\"Int64\")\n",
    "    \n",
    "    \n",
    "    # Residual Fill\n",
    "    numeric_cols = df.select_dtypes(include=[\"number\"]).columns.drop([\"carID\", \"price\"], errors='ignore')\n",
    "    for col in numeric_cols:\n",
    "        df[col] = df[col].astype(float)\n",
    "        global_mean = df[col].median()\n",
    "        df[col] = df[col].fillna(global_mean)\n",
    "        if \"Int64\" in str(df[col].dtype):\n",
    "            df[col] = df[col].round().astype(\"Int64\")\n",
    "            \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dfbf7059",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby(all_helpers, dropna=False, group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby(all_helpers, dropna=False, group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby(all_helpers, dropna=False, group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby(all_helpers, dropna=False, group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby(all_helpers, dropna=False, group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:107: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby('_combined_key', group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:107: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby('_combined_key', group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:107: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby('_combined_key', group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:107: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby('_combined_key', group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby(all_helpers, dropna=False, group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby(all_helpers, dropna=False, group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby(all_helpers, dropna=False, group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby(all_helpers, dropna=False, group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby(all_helpers, dropna=False, group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:107: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby('_combined_key', group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:107: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby('_combined_key', group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:107: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby('_combined_key', group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:107: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby('_combined_key', group_keys=False).apply(fill_group_cat, target_col)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- INICIANDO MODELAGEM LUXURY ---\n",
      "\n",
      ">>> Treinando ExtraTrees - Grupo: LUXURY\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rodrigo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:317: UserWarning: The total space of parameters 1 is smaller than n_iter=50. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores Params (LUXURY): {'n_estimators': 500, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 1.0, 'max_depth': 30}\n",
      "[LUXURY] R² Treino: 0.9783 | R² Validação: 0.9790\n",
      "[LUXURY] RMSE Treino: 1921.80€ | RMSE Validação: 1706.01€\n",
      "[LUXURY] Gap de Overfit: -11.23%\n",
      "\n",
      "--- INICIANDO MODELAGEM OTHERS ---\n",
      "\n",
      ">>> Treinando ExtraTrees - Grupo: OTHERS\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rodrigo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:317: UserWarning: The total space of parameters 1 is smaller than n_iter=50. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores Params (OTHERS): {'n_estimators': 500, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 1.0, 'max_depth': 30}\n",
      "[OTHERS] R² Treino: 0.9784 | R² Validação: 0.9783\n",
      "[OTHERS] RMSE Treino: 1012.77€ | RMSE Validação: 917.20€\n",
      "[OTHERS] Gap de Overfit: -9.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby(all_helpers, dropna=False, group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby(all_helpers, dropna=False, group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby(all_helpers, dropna=False, group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby(all_helpers, dropna=False, group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby(all_helpers, dropna=False, group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:107: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby('_combined_key', group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:107: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby('_combined_key', group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:107: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby('_combined_key', group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:107: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby('_combined_key', group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Rodrigo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Submissão 'submission_extratrees_split.csv' salva com sucesso!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, PredefinedSplit\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import ExtraTreesRegressor  # <--- MUDANÇA AQUI\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from scipy.stats import randint\n",
    "import functionsML as f # Assumindo que tens as tuas funções aqui\n",
    "\n",
    "# --- 1. CONFIGURAÇÃO E CARREGAMENTO ---\n",
    "\n",
    "train_db = pd.read_csv(\"./train.csv\")\n",
    "train_db['price_log'] = np.log1p(train_db['price'])\n",
    "\n",
    "# Split Treino / Validação\n",
    "train_set, val_set = train_test_split(train_db, test_size=0.3, random_state=42, shuffle=True)\n",
    "\n",
    "# Limpeza\n",
    "train_set = clean_data(train_set)\n",
    "val_set = clean_data(val_set)\n",
    "\n",
    "# --- 2. SEPARAÇÃO LUXURY VS OTHERS ---\n",
    "luxury_brands = ['mercedes', 'audi', 'bmw']\n",
    "mask_train = train_set['Brand'].str.lower().isin(luxury_brands)\n",
    "mask_val = val_set['Brand'].str.lower().isin(luxury_brands)\n",
    "\n",
    "# Datasets separados\n",
    "train_lux = train_set[mask_train].copy()\n",
    "train_oth = train_set[~mask_train].copy()\n",
    "val_lux = val_set[mask_val].copy()\n",
    "val_oth = val_set[~mask_val].copy()\n",
    "\n",
    "# --- 3. FUNÇÃO DE TREINO (ADAPTADA PARA EXTRA TREES) ---\n",
    "def train_and_evaluate_et(train_df, val_df, group_name):\n",
    "    # A. Target Encoding\n",
    "    mapping = train_df.groupby([\"Brand\", \"model\"])[\"price_log\"].mean().to_dict()\n",
    "    global_mean = train_df[\"price_log\"].mean()\n",
    "    \n",
    "    # B. Encoding & Prep\n",
    "    train_len = len(train_df)\n",
    "    combined = pd.concat([train_df, val_df], axis=0)\n",
    "    \n",
    "    # Target Encode\n",
    "    combined[\"Brand_model_encoded\"] = combined.apply(\n",
    "        lambda x: mapping.get((x[\"Brand\"], x[\"model\"]), global_mean), axis=1\n",
    "    )\n",
    "    \n",
    "    # One-Hot Encode\n",
    "    combined = pd.get_dummies(combined, columns=[\"Brand\", \"transmission\", \"fuelType\"], drop_first=True)\n",
    "    \n",
    "    # Separar X e y\n",
    "    drop_cols = [\"price\", \"price_log\", \"carID\", \"model\", \"previousOwners\"]\n",
    "    X_train = combined.iloc[:train_len].drop(columns=drop_cols, errors='ignore')\n",
    "    y_train = combined.iloc[:train_len][\"price_log\"]\n",
    "    X_val = combined.iloc[train_len:].drop(columns=drop_cols, errors='ignore')\n",
    "    y_val = combined.iloc[train_len:][\"price_log\"]\n",
    "    \n",
    "    # Scaling\n",
    "    train_cols = X_train.columns\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_s = pd.DataFrame(scaler.fit_transform(X_train), columns=train_cols)\n",
    "    X_val_s = pd.DataFrame(scaler.transform(X_val), columns=train_cols)\n",
    "    \n",
    "    # C. Setup para RandomizedSearch\n",
    "    X_comb = pd.concat([X_train_s, X_val_s], axis=0).reset_index(drop=True)\n",
    "    y_comb = pd.concat([y_train, y_val], axis=0).reset_index(drop=True)\n",
    "    \n",
    "    # Predefined Split (-1 = Treino, 0 = Validação)\n",
    "    ps = PredefinedSplit([-1]*len(X_train_s) + [0]*len(X_val_s))\n",
    "    \n",
    "    # --- MUDANÇA PRINCIPAL: EXTRA TREES ---\n",
    "    # bootstrap=False é comum em ExtraTrees (usa o dataset todo), mas podes testar True.\n",
    "    et_model = ExtraTreesRegressor(random_state=42, n_jobs=-1, bootstrap=False)\n",
    "    \n",
    "    # Grelha de Hiperparâmetros para Extra Trees\n",
    "    param_dist = {\n",
    "        'n_estimators': [500],\n",
    "        'max_features': [1.0],\n",
    "        'max_depth': [30],\n",
    "        'min_samples_leaf': [1],\n",
    "        'min_samples_split': [10]\n",
    "    }\n",
    "    \n",
    "    search = RandomizedSearchCV(\n",
    "        estimator=et_model, \n",
    "        param_distributions=param_dist, \n",
    "        n_iter=50,  # ExtraTrees é rápido, 20 iterações é tranquilo\n",
    "        cv=ps, \n",
    "        scoring='neg_root_mean_squared_error', \n",
    "        n_jobs=-1, \n",
    "        random_state=42,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n>>> Treinando ExtraTrees - Grupo: {group_name}\")\n",
    "    search.fit(X_comb, y_comb)\n",
    "    best_et = search.best_estimator_\n",
    "    print(f\"Melhores Params ({group_name}): {search.best_params_}\")\n",
    "    \n",
    "    # D. Análise de Overfit\n",
    "    p_train = best_et.predict(X_train_s)\n",
    "    p_val = best_et.predict(X_val_s)\n",
    "    \n",
    "    # Métricas\n",
    "    r2_train = r2_score(y_train, p_train)\n",
    "    r2_val = r2_score(y_val, p_val)\n",
    "    \n",
    "    # Converter Log -> Reais para RMSE\n",
    "    rmse_train = np.sqrt(mean_squared_error(np.expm1(y_train), np.expm1(p_train)))\n",
    "    rmse_val = np.sqrt(mean_squared_error(np.expm1(y_val), np.expm1(p_val)))\n",
    "    \n",
    "    print(f\"[{group_name}] R² Treino: {r2_train:.4f} | R² Validação: {r2_val:.4f}\")\n",
    "    print(f\"[{group_name}] RMSE Treino: {rmse_train:.2f}€ | RMSE Validação: {rmse_val:.2f}€\")\n",
    "    \n",
    "    gap = (rmse_val - rmse_train) / rmse_train * 100\n",
    "    print(f\"[{group_name}] Gap de Overfit: {gap:.2f}%\")\n",
    "    \n",
    "    return best_et, scaler, mapping, global_mean, train_cols\n",
    "\n",
    "# --- 4. EXECUÇÃO DOS GRUPOS ---\n",
    "print(\"--- INICIANDO MODELAGEM LUXURY ---\")\n",
    "model_lux_et, sc_lux, map_lux, mean_lux, cols_lux = train_and_evaluate_et(train_lux, val_lux, \"LUXURY\")\n",
    "\n",
    "print(\"\\n--- INICIANDO MODELAGEM OTHERS ---\")\n",
    "model_oth_et, sc_oth, map_oth, mean_oth, cols_oth = train_and_evaluate_et(train_oth, val_oth, \"OTHERS\")\n",
    "\n",
    "# --- 5. PREDIÇÃO TESTE FINAL ---\n",
    "test_db = pd.read_csv(\"./test.csv\")\n",
    "test_clean = clean_data(test_db) # Usa a tua função de limpeza\n",
    "\n",
    "def predict_group(df, model, scaler, mapping, g_mean, train_cols):\n",
    "    if df.empty: return pd.DataFrame()\n",
    "    \n",
    "    df_enc = df.copy()\n",
    "    # Target Encode com mapping do treino\n",
    "    df_enc[\"Brand_model_encoded\"] = df_enc.apply(lambda x: mapping.get((x[\"Brand\"], x[\"model\"]), g_mean), axis=1)\n",
    "    \n",
    "    # One Hot\n",
    "    df_enc = pd.get_dummies(df_enc, columns=[\"Brand\", \"transmission\", \"fuelType\"], drop_first=True)\n",
    "    \n",
    "    # Alinhamento\n",
    "    X_test = df_enc.reindex(columns=train_cols, fill_value=0)\n",
    "    \n",
    "    # Scaling\n",
    "    X_test_s = scaler.transform(X_test)\n",
    "    \n",
    "    # Prever e inverter log\n",
    "    preds = np.expm1(model.predict(X_test_s))\n",
    "    \n",
    "    return pd.DataFrame({\"carID\": df[\"carID\"], \"price\": preds})\n",
    "\n",
    "# Separar teste\n",
    "mask_test = test_clean['Brand'].str.lower().isin(luxury_brands)\n",
    "\n",
    "# Prever separadamente\n",
    "sub_lux = predict_group(test_clean[mask_test], model_lux_et, sc_lux, map_lux, mean_lux, cols_lux)\n",
    "sub_oth = predict_group(test_clean[~mask_test], model_oth_et, sc_oth, map_oth, mean_oth, cols_oth)\n",
    "\n",
    "# Juntar e Salvar\n",
    "submission = pd.concat([sub_lux, sub_oth]).sort_values(\"carID\")\n",
    "submission.to_csv(\"submission_extratrees_split.csv\", index=False)\n",
    "print(\"\\nSubmissão 'submission_extratrees_split.csv' salva com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0b9c02e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby(all_helpers, dropna=False, group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby(all_helpers, dropna=False, group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby(all_helpers, dropna=False, group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby(all_helpers, dropna=False, group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby(all_helpers, dropna=False, group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:107: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby('_combined_key', group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:107: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby('_combined_key', group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:107: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby('_combined_key', group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:107: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby('_combined_key', group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby(all_helpers, dropna=False, group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby(all_helpers, dropna=False, group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby(all_helpers, dropna=False, group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby(all_helpers, dropna=False, group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby(all_helpers, dropna=False, group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:107: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby('_combined_key', group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:107: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby('_combined_key', group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:107: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby('_combined_key', group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:107: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby('_combined_key', group_keys=False).apply(fill_group_cat, target_col)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- INICIANDO MODELAGEM LUXURY (HistGB) ---\n",
      "\n",
      ">>> Treinando HistGB - Grupo: LUXURY\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rodrigo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:317: UserWarning: The total space of parameters 1 is smaller than n_iter=50. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores Params (LUXURY): {'max_leaf_nodes': 80, 'max_iter': 3000, 'max_features': 0.3, 'max_depth': 10, 'learning_rate': 0.05, 'l2_regularization': 0.5}\n",
      "[LUXURY] R² Treino: 0.9793 | R² Validação: 0.9800\n",
      "[LUXURY] RMSE Treino: 1787.06€ | RMSE Validação: 1677.48€\n",
      "[LUXURY] Gap de Overfit: -6.13%\n",
      "\n",
      "--- INICIANDO MODELAGEM OTHERS (HistGB) ---\n",
      "\n",
      ">>> Treinando HistGB - Grupo: OTHERS\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rodrigo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:317: UserWarning: The total space of parameters 1 is smaller than n_iter=50. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores Params (OTHERS): {'max_leaf_nodes': 80, 'max_iter': 3000, 'max_features': 0.3, 'max_depth': 10, 'learning_rate': 0.05, 'l2_regularization': 0.5}\n",
      "[OTHERS] R² Treino: 0.9760 | R² Validação: 0.9758\n",
      "[OTHERS] RMSE Treino: 1054.59€ | RMSE Validação: 972.24€\n",
      "[OTHERS] Gap de Overfit: -7.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby(all_helpers, dropna=False, group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby(all_helpers, dropna=False, group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby(all_helpers, dropna=False, group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby(all_helpers, dropna=False, group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby(all_helpers, dropna=False, group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:107: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby('_combined_key', group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:107: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby('_combined_key', group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:107: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby('_combined_key', group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:107: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby('_combined_key', group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but HistGradientBoostingRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Rodrigo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but HistGradientBoostingRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Submissão 'submission_histgb_split.csv' salva com sucesso!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, PredefinedSplit\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor # <--- O NOSSO MODELO\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import functionsML as f \n",
    "\n",
    "\n",
    "train_db = pd.read_csv(\"./train.csv\")\n",
    "train_db['price_log'] = np.log1p(train_db['price'])\n",
    "\n",
    "# Split Treino / Validação\n",
    "train_set, val_set = train_test_split(train_db, test_size=0.3, random_state=42, shuffle=True)\n",
    "\n",
    "# Limpeza\n",
    "train_set = clean_data(train_set)\n",
    "val_set = clean_data(val_set)\n",
    "\n",
    "# --- 2. SEPARAÇÃO LUXURY VS OTHERS ---\n",
    "luxury_brands = ['mercedes', 'audi', 'bmw']\n",
    "mask_train = train_set['Brand'].str.lower().isin(luxury_brands)\n",
    "mask_val = val_set['Brand'].str.lower().isin(luxury_brands)\n",
    "\n",
    "# Datasets separados\n",
    "train_lux = train_set[mask_train].copy()\n",
    "train_oth = train_set[~mask_train].copy()\n",
    "val_lux = val_set[mask_val].copy()\n",
    "val_oth = val_set[~mask_val].copy()\n",
    "\n",
    "# --- 3. FUNÇÃO DE TREINO (ADAPTADA PARA HIST GRADIENT BOOSTING) ---\n",
    "def train_and_evaluate_hgb(train_df, val_df, group_name):\n",
    "    # A. Target Encoding\n",
    "    mapping = train_df.groupby([\"Brand\", \"model\"])[\"price_log\"].mean().to_dict()\n",
    "    global_mean = train_df[\"price_log\"].mean()\n",
    "    \n",
    "    # B. Encoding & Prep\n",
    "    train_len = len(train_df)\n",
    "    combined = pd.concat([train_df, val_df], axis=0)\n",
    "    \n",
    "    # Target Encode\n",
    "    combined[\"Brand_model_encoded\"] = combined.apply(\n",
    "        lambda x: mapping.get((x[\"Brand\"], x[\"model\"]), global_mean), axis=1\n",
    "    )\n",
    "    \n",
    "    # One-Hot Encode\n",
    "    combined = pd.get_dummies(combined, columns=[\"Brand\", \"transmission\", \"fuelType\"], drop_first=True)\n",
    "    \n",
    "    # Separar X e y\n",
    "    drop_cols = [\"price\", \"price_log\", \"carID\", \"model\", \"previousOwners\"]\n",
    "    X_train = combined.iloc[:train_len].drop(columns=drop_cols, errors='ignore')\n",
    "    y_train = combined.iloc[:train_len][\"price_log\"]\n",
    "    X_val = combined.iloc[train_len:].drop(columns=drop_cols, errors='ignore')\n",
    "    y_val = combined.iloc[train_len:][\"price_log\"]\n",
    "    \n",
    "    # Scaling (O HistGB não obriga, mas ajuda a manter consistência com o resto do projeto)\n",
    "    train_cols = X_train.columns\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_s = pd.DataFrame(scaler.fit_transform(X_train), columns=train_cols)\n",
    "    X_val_s = pd.DataFrame(scaler.transform(X_val), columns=train_cols)\n",
    "    \n",
    "    # C. Setup para RandomizedSearch\n",
    "    X_comb = pd.concat([X_train_s, X_val_s], axis=0).reset_index(drop=True)\n",
    "    y_comb = pd.concat([y_train, y_val], axis=0).reset_index(drop=True)\n",
    "    \n",
    "    # Predefined Split (-1 = Treino, 0 = Validação)\n",
    "    ps = PredefinedSplit([-1]*len(X_train_s) + [0]*len(X_val_s))\n",
    "    \n",
    "    # --- MODELO HIST GRADIENT BOOSTING ---\n",
    "    hgb_model = HistGradientBoostingRegressor(\n",
    "        loss='squared_error',\n",
    "        random_state=42,\n",
    "        early_stopping=False # Desligamos o interno porque usamos CV fixo\n",
    "    )\n",
    "    \n",
    "    # Grelha de Hiperparâmetros (Os teus melhores parâmetros)\n",
    "    param_dist = {\n",
    "        'l2_regularization': [0.5], \n",
    "    \n",
    "        # 2. Controlar a Complexidade\n",
    "        # 118 folhas é muito. Vamos testar valores mais baixos.\n",
    "        'max_leaf_nodes': [80], \n",
    "        'max_depth': [10], # Limitar a profundidade também\n",
    "    \n",
    "        # 3. Features e Learning Rate\n",
    "        'learning_rate': [0.05],\n",
    "        'max_iter': [3000],\n",
    "    \n",
    "        # IMPORTANTE: Tentar simular o 'log2' do GB\n",
    "        # Baixar isto obriga cada árvore a ser mais independente\n",
    "        'max_features': [0.3] \n",
    "\n",
    "    }\n",
    "    \n",
    "    search = RandomizedSearchCV(\n",
    "        estimator=hgb_model, \n",
    "        param_distributions=param_dist, \n",
    "        n_iter=50, \n",
    "        cv=ps, \n",
    "        scoring='neg_root_mean_squared_error', \n",
    "        n_jobs=-1, \n",
    "        random_state=42,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n>>> Treinando HistGB - Grupo: {group_name}\")\n",
    "    search.fit(X_comb, y_comb)\n",
    "    best_hbg = search.best_estimator_\n",
    "    print(f\"Melhores Params ({group_name}): {search.best_params_}\")\n",
    "    \n",
    "    # D. Análise de Overfit\n",
    "    p_train = best_hbg.predict(X_train_s)\n",
    "    p_val = best_hbg.predict(X_val_s)\n",
    "    \n",
    "    # Métricas\n",
    "    r2_train = r2_score(y_train, p_train)\n",
    "    r2_val = r2_score(y_val, p_val)\n",
    "    \n",
    "    # Converter Log -> Reais para RMSE\n",
    "    rmse_train = np.sqrt(mean_squared_error(np.expm1(y_train), np.expm1(p_train)))\n",
    "    rmse_val = np.sqrt(mean_squared_error(np.expm1(y_val), np.expm1(p_val)))\n",
    "    \n",
    "    print(f\"[{group_name}] R² Treino: {r2_train:.4f} | R² Validação: {r2_val:.4f}\")\n",
    "    print(f\"[{group_name}] RMSE Treino: {rmse_train:.2f}€ | RMSE Validação: {rmse_val:.2f}€\")\n",
    "    \n",
    "    gap = (rmse_val - rmse_train) / rmse_train * 100\n",
    "    print(f\"[{group_name}] Gap de Overfit: {gap:.2f}%\")\n",
    "    \n",
    "    return best_hbg, scaler, mapping, global_mean, train_cols\n",
    "\n",
    "# --- 4. EXECUÇÃO DOS GRUPOS ---\n",
    "print(\"--- INICIANDO MODELAGEM LUXURY (HistGB) ---\")\n",
    "model_lux_hgb, sc_lux, map_lux, mean_lux, cols_lux = train_and_evaluate_hgb(train_lux, val_lux, \"LUXURY\")\n",
    "\n",
    "print(\"\\n--- INICIANDO MODELAGEM OTHERS (HistGB) ---\")\n",
    "model_oth_hgb, sc_oth, map_oth, mean_oth, cols_oth = train_and_evaluate_hgb(train_oth, val_oth, \"OTHERS\")\n",
    "\n",
    "# --- 5. PREDIÇÃO TESTE FINAL ---\n",
    "test_db = pd.read_csv(\"./test.csv\")\n",
    "test_clean = clean_data(test_db) \n",
    "\n",
    "def predict_group(df, model, scaler, mapping, g_mean, train_cols):\n",
    "    if df.empty: return pd.DataFrame()\n",
    "    \n",
    "    df_enc = df.copy()\n",
    "    # Target Encode\n",
    "    df_enc[\"Brand_model_encoded\"] = df_enc.apply(lambda x: mapping.get((x[\"Brand\"], x[\"model\"]), g_mean), axis=1)\n",
    "    \n",
    "    # One Hot\n",
    "    df_enc = pd.get_dummies(df_enc, columns=[\"Brand\", \"transmission\", \"fuelType\"], drop_first=True)\n",
    "    \n",
    "    # Alinhamento\n",
    "    X_test = df_enc.reindex(columns=train_cols, fill_value=0)\n",
    "    \n",
    "    # Scaling\n",
    "    X_test_s = scaler.transform(X_test)\n",
    "    \n",
    "    # Prever e inverter log\n",
    "    preds = np.expm1(model.predict(X_test_s))\n",
    "    \n",
    "    return pd.DataFrame({\"carID\": df[\"carID\"], \"price\": preds})\n",
    "\n",
    "# Separar teste\n",
    "mask_test = test_clean['Brand'].str.lower().isin(luxury_brands)\n",
    "\n",
    "# Prever separadamente\n",
    "sub_lux = predict_group(test_clean[mask_test], model_lux_hgb, sc_lux, map_lux, mean_lux, cols_lux)\n",
    "sub_oth = predict_group(test_clean[~mask_test], model_oth_hgb, sc_oth, map_oth, mean_oth, cols_oth)\n",
    "\n",
    "# Juntar e Salvar\n",
    "submission = pd.concat([sub_lux, sub_oth]).sort_values(\"carID\")\n",
    "submission.to_csv(\"submission_histgb_split.csv\", index=False)\n",
    "print(\"\\nSubmissão 'submission_histgb_split.csv' salva com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "193b1a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby(all_helpers, dropna=False, group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby(all_helpers, dropna=False, group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby(all_helpers, dropna=False, group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby(all_helpers, dropna=False, group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby(all_helpers, dropna=False, group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:107: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby('_combined_key', group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:107: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby('_combined_key', group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:107: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby('_combined_key', group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:107: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby('_combined_key', group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby(all_helpers, dropna=False, group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby(all_helpers, dropna=False, group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby(all_helpers, dropna=False, group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby(all_helpers, dropna=False, group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby(all_helpers, dropna=False, group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:107: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby('_combined_key', group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:107: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby('_combined_key', group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:107: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby('_combined_key', group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:107: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby('_combined_key', group_keys=False).apply(fill_group_cat, target_col)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Treinando Grupo: LUXURY\n",
      "[LUXURY] R² Treino: 0.9846 | R² Validação: 0.9846\n",
      "[LUXURY] RMSE Treino: 1772.40€ | RMSE Validação: 1543.96€\n",
      "[LUXURY] Gap de Overfit: -12.89%\n",
      "\n",
      ">>> Treinando Grupo: OTHERS\n",
      "[OTHERS] R² Treino: 0.9788 | R² Validação: 0.9787\n",
      "[OTHERS] RMSE Treino: 983.12€ | RMSE Validação: 908.91€\n",
      "[OTHERS] Gap de Overfit: -7.55%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby(all_helpers, dropna=False, group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby(all_helpers, dropna=False, group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby(all_helpers, dropna=False, group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby(all_helpers, dropna=False, group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby(all_helpers, dropna=False, group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:107: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby('_combined_key', group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:107: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby('_combined_key', group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:107: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby('_combined_key', group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:107: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby('_combined_key', group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Rodrigo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Submissão salva com sucesso!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, PredefinedSplit\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from scipy.stats import randint\n",
    "\n",
    "\n",
    "\n",
    "# --- 2. CARREGAMENTO E SPLIT ---\n",
    "train_db = pd.read_csv(\"./train.csv\")\n",
    "train_db['price_log'] = np.log1p(train_db['price'])\n",
    "\n",
    "train_set, val_set = train_test_split(train_db, test_size=0.3, random_state=42, shuffle=True)\n",
    "\n",
    "train_set = clean_data(train_set)\n",
    "val_set = clean_data(val_set)\n",
    "\n",
    "luxury_brands = ['mercedes', 'audi', 'bmw']\n",
    "mask_train = train_set['Brand'].str.lower().isin(luxury_brands)\n",
    "mask_val = val_set['Brand'].str.lower().isin(luxury_brands)\n",
    "\n",
    "train_lux = train_set[mask_train].copy()\n",
    "train_oth = train_set[~mask_train].copy()\n",
    "val_lux = val_set[mask_val].copy()\n",
    "val_oth = val_set[~mask_val].copy()\n",
    "\n",
    "# --- 3. FUNÇÃO PRINCIPAL COM TESTE DE OVERFIT ---\n",
    "def train_and_evaluate(train_df, val_df, group_name):\n",
    "    # A. Target Encoding\n",
    "    mapping = train_df.groupby([\"Brand\", \"model\"])[\"price_log\"].mean().to_dict()\n",
    "    global_mean = train_df[\"price_log\"].mean()\n",
    "    \n",
    "    # B. Encoding & Prep\n",
    "    train_len = len(train_df)\n",
    "    combined = pd.concat([train_df, val_df], axis=0)\n",
    "    combined[\"Brand_model_encoded\"] = combined.apply(\n",
    "        lambda x: mapping.get((x[\"Brand\"], x[\"model\"]), global_mean), axis=1\n",
    "    )\n",
    "    combined = pd.get_dummies(combined, columns=[\"Brand\", \"transmission\", \"fuelType\"], drop_first=True)\n",
    "    \n",
    "    drop_cols = [\"price\", \"price_log\", \"carID\", \"model\", \"previousOwners\"]\n",
    "    X_train = combined.iloc[:train_len].drop(columns=drop_cols, errors='ignore')\n",
    "    y_train = combined.iloc[:train_len][\"price_log\"]\n",
    "    X_val = combined.iloc[train_len:].drop(columns=drop_cols, errors='ignore')\n",
    "    y_val = combined.iloc[train_len:][\"price_log\"]\n",
    "    \n",
    "    train_cols = X_train.columns\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_s = pd.DataFrame(scaler.fit_transform(X_train), columns=train_cols)\n",
    "    X_val_s = pd.DataFrame(scaler.transform(X_val), columns=train_cols)\n",
    "    \n",
    "    # C. Randomized Search\n",
    "    X_comb = pd.concat([X_train_s, X_val_s], axis=0).reset_index(drop=True)\n",
    "    y_comb = pd.concat([y_train, y_val], axis=0).reset_index(drop=True)\n",
    "    ps = PredefinedSplit([-1]*len(X_train_s) + [0]*len(X_val_s))\n",
    "    \n",
    "    rf = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "    param_dist = {\n",
    "        'n_estimators': [500,1000],\n",
    "        'max_depth': [10,15, 20, 30, None],\n",
    "        'min_samples_split': randint(2, 10),\n",
    "        'min_samples_leaf': randint(1, 4)\n",
    "    }\n",
    "    \n",
    "    search = RandomizedSearchCV(\n",
    "        estimator=rf, param_distributions=param_dist, n_iter=50, \n",
    "        cv=ps, scoring='neg_root_mean_squared_error', n_jobs=-1, random_state=42\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n>>> Treinando Grupo: {group_name}\")\n",
    "    search.fit(X_comb, y_comb)\n",
    "    best_model = search.best_estimator_\n",
    "    \n",
    "    # D. MÁGICA DO OVERFIT: Comparar Train vs Val\n",
    "    p_train = best_model.predict(X_train_s)\n",
    "    p_val = best_model.predict(X_val_s)\n",
    "    \n",
    "    # Métricas no Log (para R2) e Original (para RMSE em Euros)\n",
    "    r2_train = r2_score(y_train, p_train)\n",
    "    r2_val = r2_score(y_val, p_val)\n",
    "    \n",
    "    rmse_train = np.sqrt(mean_squared_error(np.expm1(y_train), np.expm1(p_train)))\n",
    "    rmse_val = np.sqrt(mean_squared_error(np.expm1(y_val), np.expm1(p_val)))\n",
    "    \n",
    "    print(f\"[{group_name}] R² Treino: {r2_train:.4f} | R² Validação: {r2_val:.4f}\")\n",
    "    print(f\"[{group_name}] RMSE Treino: {rmse_train:.2f}€ | RMSE Validação: {rmse_val:.2f}€\")\n",
    "    \n",
    "    gap = (rmse_val - rmse_train) / rmse_train * 100\n",
    "    print(f\"[{group_name}] Gap de Overfit: {gap:.2f}%\")\n",
    "    \n",
    "    return best_model, scaler, mapping, global_mean, train_cols\n",
    "\n",
    "# --- 4. EXECUÇÃO ---\n",
    "model_lux_rf, sc_lux, map_lux, mean_lux, cols_lux = train_and_evaluate(train_lux, val_lux, \"LUXURY\")\n",
    "model_oth_rf, sc_oth, map_oth, mean_oth, cols_oth = train_and_evaluate(train_oth, val_oth, \"OTHERS\")\n",
    "\n",
    "# --- 5. PREDIÇÃO TESTE FINAL ---\n",
    "test_db = pd.read_csv(\"./test.csv\")\n",
    "test_clean = clean_data(test_db)\n",
    "\n",
    "def predict_group(df, model, scaler, mapping, g_mean, train_cols):\n",
    "    if df.empty: return pd.DataFrame()\n",
    "    df_enc = df.copy()\n",
    "    df_enc[\"Brand_model_encoded\"] = df_enc.apply(lambda x: mapping.get((x[\"Brand\"], x[\"model\"]), g_mean), axis=1)\n",
    "    df_enc = pd.get_dummies(df_enc, columns=[\"Brand\", \"transmission\", \"fuelType\"], drop_first=True)\n",
    "    X_test = df_enc.reindex(columns=train_cols, fill_value=0)\n",
    "    X_test_s = scaler.transform(X_test)\n",
    "    preds = np.expm1(model.predict(X_test_s))\n",
    "    return pd.DataFrame({\"carID\": df[\"carID\"], \"price\": preds})\n",
    "\n",
    "mask_test = test_clean['Brand'].str.lower().isin(luxury_brands)\n",
    "sub_lux = predict_group(test_clean[mask_test], model_lux_rf, sc_lux, map_lux, mean_lux, cols_lux)\n",
    "sub_oth = predict_group(test_clean[~mask_test], model_oth_rf, sc_oth, map_oth, mean_oth, cols_oth)\n",
    "\n",
    "submission = pd.concat([sub_lux, sub_oth]).sort_values(\"carID\")\n",
    "submission.to_csv(\"submission_overfit_checked.csv\", index=False)\n",
    "print(\"\\nSubmissão salva com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0e9951b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> A preparar dados LUXURY...\n",
      ">>> A preparar dados OTHERS...\n",
      "\n",
      "=== ENSEMBLE LUXURY ===\n",
      "\n",
      "🧠 Otimizando Pesos para LUXURY...\n",
      "Fitting 1 folds for each of 50 candidates, totalling 50 fits\n",
      "🏆 Melhor RMSE (LUXURY): 0.10901\n",
      "⚖️ Pesos Ideais: [('RF', 11), ('ET', 13), ('HGB', 59)]\n",
      "\n",
      "=== ENSEMBLE OTHERS ===\n",
      "\n",
      "🧠 Otimizando Pesos para OTHERS...\n",
      "Fitting 1 folds for each of 50 candidates, totalling 50 fits\n",
      "🏆 Melhor RMSE (OTHERS): 0.10124\n",
      "⚖️ Pesos Ideais: [('RF', 21), ('ET', 61), ('HGB', 97)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby(all_helpers, dropna=False, group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby(all_helpers, dropna=False, group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby(all_helpers, dropna=False, group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby(all_helpers, dropna=False, group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby(all_helpers, dropna=False, group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:107: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby('_combined_key', group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:107: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby('_combined_key', group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:107: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby('_combined_key', group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:107: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby('_combined_key', group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Rodrigo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Rodrigo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but HistGradientBoostingRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Rodrigo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Rodrigo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Rodrigo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but HistGradientBoostingRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Submissão 'submission_ensemble_split_optimized.csv' criada com sucesso!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV, PredefinedSplit\n",
    "\n",
    "# --- 1. RECOLHER OS MODELOS JÁ TREINADOS ---\n",
    "# Tens de garantir que estas variáveis existem. \n",
    "# Se sobrescreveste 'model_lux' nas células anteriores, tens de voltar atrás e correr os treinos \n",
    "# (ou atribuir nomes diferentes) para teres os 3 disponíveis simultaneamente.\n",
    "\n",
    "# Exemplo de como devem estar organizados (substitui pelas tuas variáveis reais):\n",
    "models_luxury = {\n",
    "    'RF': model_lux_rf,   # O teu melhor Random Forest (Luxury)\n",
    "    'ET': model_lux_et,   # O teu melhor Extra Trees (Luxury)\n",
    "    'HGB': model_lux_hgb  # O teu melhor HistGradientBoosting (Luxury)\n",
    "}\n",
    "\n",
    "models_others = {\n",
    "    'RF': model_oth_rf,   # O teu melhor Random Forest (Others)\n",
    "    'ET': model_oth_et,   # O teu melhor Extra Trees (Others)\n",
    "    'HGB': model_oth_hgb  # O teu melhor HistGradientBoosting (Others)\n",
    "}\n",
    "\n",
    "# --- 2. PREPARAR DADOS (Recuperar X e y para cada grupo) ---\n",
    "# Precisamos disto para o 'fit' do VotingRegressor conseguir calcular os erros e ajustar pesos\n",
    "\n",
    "# (Assume-se que train_lux, val_lux, train_oth, val_oth já existem da célula anterior)\n",
    "\n",
    "def prepare_data_for_ensemble(train_df, val_df):\n",
    "    # Target Encoding (Usar lógica rápida)\n",
    "    mapping = train_df.groupby([\"Brand\", \"model\"])[\"price_log\"].mean().to_dict()\n",
    "    global_mean = train_df[\"price_log\"].mean()\n",
    "    \n",
    "    combined = pd.concat([train_df, val_df], axis=0)\n",
    "    combined[\"Brand_model_encoded\"] = combined.apply(\n",
    "        lambda x: mapping.get((x[\"Brand\"], x[\"model\"]), global_mean), axis=1\n",
    "    )\n",
    "    combined = pd.get_dummies(combined, columns=[\"Brand\", \"transmission\", \"fuelType\"], drop_first=True)\n",
    "    \n",
    "    drop_cols = [\"price\", \"price_log\", \"carID\", \"model\", \"previousOwners\"]\n",
    "    train_len = len(train_df)\n",
    "    \n",
    "    X = combined.drop(columns=drop_cols, errors='ignore')\n",
    "    y = combined[\"price_log\"]\n",
    "    \n",
    "    # Scaling (Obrigatório para consistência)\n",
    "    scaler = MinMaxScaler()\n",
    "    X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "    \n",
    "    # Separar para criar o PredefinedSplit corretamente\n",
    "    X_train_s = X_scaled.iloc[:train_len]\n",
    "    X_val_s = X_scaled.iloc[train_len:]\n",
    "    y_train = y.iloc[:train_len]\n",
    "    y_val = y.iloc[train_len:]\n",
    "    \n",
    "    # Juntar tudo para o RandomizedSearch\n",
    "    X_final = pd.concat([X_train_s, X_val_s], axis=0).reset_index(drop=True)\n",
    "    y_final = pd.concat([y_train, y_val], axis=0).reset_index(drop=True)\n",
    "    \n",
    "    # Criar PS\n",
    "    split_index = ([-1] * len(X_train_s)) + ([0] * len(X_val_s))\n",
    "    ps = PredefinedSplit(test_fold=split_index)\n",
    "    \n",
    "    return X_final, y_final, ps, scaler, mapping, global_mean, X_train_s.columns\n",
    "\n",
    "# Preparar dados Luxo\n",
    "print(\">>> A preparar dados LUXURY...\")\n",
    "X_lux_comb, y_lux_comb, ps_lux, sc_lux, map_lux, mean_lux, cols_lux = prepare_data_for_ensemble(train_lux, val_lux)\n",
    "\n",
    "# Preparar dados Outros\n",
    "print(\">>> A preparar dados OTHERS...\")\n",
    "X_oth_comb, y_oth_comb, ps_oth, sc_oth, map_oth, mean_oth, cols_oth = prepare_data_for_ensemble(train_oth, val_oth)\n",
    "\n",
    "\n",
    "# --- 3. FUNÇÃO DE OTIMIZAÇÃO DE PESOS (A MÁGICA) ---\n",
    "def optimize_ensemble_weights(models_dict, X, y, ps, group_name):\n",
    "    estimators_list = list(models_dict.items())\n",
    "    model_names = [name for name, _ in estimators_list]\n",
    "    n_models = len(estimators_list)\n",
    "    \n",
    "    # Gerar combinações de pesos\n",
    "    random.seed(42)\n",
    "    weights_combinations = []\n",
    "    for _ in range(100): # 100 tentativas\n",
    "        w = []\n",
    "        for _ in range(n_models):\n",
    "            if random.random() < 0.2: w.append(0) # 20% chance de dropar modelo\n",
    "            else: w.append(random.randint(1, 100))\n",
    "        if sum(w) == 0: w[0] = 50\n",
    "        weights_combinations.append(w)\n",
    "    weights_combinations.append([1] * n_models) # Média simples\n",
    "    \n",
    "    # Configurar Voting\n",
    "    voting_base = VotingRegressor(estimators=estimators_list, n_jobs=-1)\n",
    "    \n",
    "    param_grid = {'weights': weights_combinations}\n",
    "    \n",
    "    search = RandomizedSearchCV(\n",
    "        estimator=voting_base,\n",
    "        param_distributions=param_grid,\n",
    "        n_iter=50,\n",
    "        cv=ps,\n",
    "        scoring='neg_root_mean_squared_error',\n",
    "        verbose=1,\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n🧠 Otimizando Pesos para {group_name}...\")\n",
    "    search.fit(X, y)\n",
    "    \n",
    "    # Relatório\n",
    "    best_weights = search.best_params_['weights']\n",
    "    print(f\"🏆 Melhor RMSE ({group_name}): {-search.best_score_:.5f}\")\n",
    "    print(f\"⚖️ Pesos Ideais: {list(zip(model_names, best_weights))}\")\n",
    "    \n",
    "    return search.best_estimator_\n",
    "\n",
    "# --- 4. EXECUTAR OTIMIZAÇÃO ---\n",
    "print(\"\\n=== ENSEMBLE LUXURY ===\")\n",
    "ensemble_lux = optimize_ensemble_weights(models_luxury, X_lux_comb, y_lux_comb, ps_lux, \"LUXURY\")\n",
    "\n",
    "print(\"\\n=== ENSEMBLE OTHERS ===\")\n",
    "ensemble_oth = optimize_ensemble_weights(models_others, X_oth_comb, y_oth_comb, ps_oth, \"OTHERS\")\n",
    "\n",
    "\n",
    "# --- 5. SUBMISSÃO FINAL (ENSEMBLE SPLIT) ---\n",
    "test_db = pd.read_csv(\"./test.csv\")\n",
    "test_clean = clean_data(test_db)\n",
    "\n",
    "def predict_ensemble(df, model, scaler, mapping, g_mean, train_cols):\n",
    "    if df.empty: return pd.DataFrame()\n",
    "    df_enc = df.copy()\n",
    "    df_enc[\"Brand_model_encoded\"] = df_enc.apply(lambda x: mapping.get((x[\"Brand\"], x[\"model\"]), g_mean), axis=1)\n",
    "    df_enc = pd.get_dummies(df_enc, columns=[\"Brand\", \"transmission\", \"fuelType\"], drop_first=True)\n",
    "    X_test = df_enc.reindex(columns=train_cols, fill_value=0)\n",
    "    X_test_s = scaler.transform(X_test)\n",
    "    preds = np.expm1(model.predict(X_test_s))\n",
    "    return pd.DataFrame({\"carID\": df[\"carID\"], \"price\": preds})\n",
    "\n",
    "mask_test = test_clean['Brand'].str.lower().isin(['mercedes', 'audi', 'bmw'])\n",
    "\n",
    "sub_lux = predict_ensemble(test_clean[mask_test], ensemble_lux, sc_lux, map_lux, mean_lux, cols_lux)\n",
    "sub_oth = predict_ensemble(test_clean[~mask_test], ensemble_oth, sc_oth, map_oth, mean_oth, cols_oth)\n",
    "\n",
    "submission = pd.concat([sub_lux, sub_oth]).sort_values(\"carID\")\n",
    "submission.to_csv(\"submission_ensemble_split_optimized.csv\", index=False)\n",
    "print(\"\\n✅ Submissão 'submission_ensemble_split_optimized.csv' criada com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e115fce9",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "98a180a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby(all_helpers, dropna=False, group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby(all_helpers, dropna=False, group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby(all_helpers, dropna=False, group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby(all_helpers, dropna=False, group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby(all_helpers, dropna=False, group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:107: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby('_combined_key', group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:107: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby('_combined_key', group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:107: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby('_combined_key', group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:107: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby('_combined_key', group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby(all_helpers, dropna=False, group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby(all_helpers, dropna=False, group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby(all_helpers, dropna=False, group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby(all_helpers, dropna=False, group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby(all_helpers, dropna=False, group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:107: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby('_combined_key', group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:107: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby('_combined_key', group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:107: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby('_combined_key', group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:107: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby('_combined_key', group_keys=False).apply(fill_group_cat, target_col)\n"
     ]
    }
   ],
   "source": [
    "# 1. Load Data\n",
    "train_db = pd.read_csv(\"./train.csv\")\n",
    "# Important: Apply log to the target right at the start (if that is the strategy)\n",
    "train_db['price'] = np.log1p(train_db['price'])\n",
    "\n",
    "# 2. HOLDOUT SPLIT (Initial Split)\n",
    "# Here we ensure that validation data never sees the training data\n",
    "train_set, val_set = train_test_split(train_db, test_size=0.3, random_state=42, shuffle=True)\n",
    "\n",
    "# 3. Independent Cleaning (Clean Data)\n",
    "train_set = clean_data(train_set)\n",
    "val_set = clean_data(val_set)\n",
    "\n",
    "# 4. ENCODING & SCALING (Where Data Leakage occurs if not careful)\n",
    "\n",
    "# A. One-Hot Encoding\n",
    "# We must ensure columns match. We concatenate just to generate dummies, then separate again.\n",
    "train_len = len(train_set)\n",
    "combined_temp = pd.concat([train_set, val_set], axis=0)\n",
    "\n",
    "combined_temp = pd.get_dummies(combined_temp, columns=[\"Brand\", \"transmission\", \"fuelType\"], drop_first=True)\n",
    "\n",
    "# Split back to Train and Validation\n",
    "train_set_encoded = combined_temp.iloc[:train_len].copy()\n",
    "val_set_encoded = combined_temp.iloc[train_len:].copy()\n",
    "\n",
    "# B. Target Encoding (FIT on Train, TRANSFORM on Train and Validation)\n",
    "# Calculate means on Train\n",
    "mapping = train_set.groupby([\"Brand\", \"model\"])[\"price\"].mean().to_dict()\n",
    "global_mean = train_set[\"price\"].mean()\n",
    "\n",
    "# Apply to Train\n",
    "train_set_encoded[\"Brand_model_encoded\"] = train_set.apply(\n",
    "    lambda x: mapping.get((x[\"Brand\"], x[\"model\"]), global_mean), axis=1\n",
    ")\n",
    "\n",
    "# Apply to Validation (using the training mapping!)\n",
    "val_set_encoded[\"Brand_model_encoded\"] = val_set.apply(\n",
    "    lambda x: mapping.get((x[\"Brand\"], x[\"model\"]), global_mean), axis=1\n",
    ")\n",
    "\n",
    "# 5. FINAL PREPARATION (X and y)\n",
    "drop_cols = [\"price\", \"carID\", \"model\", \"previousOwners\"] # Columns to remove\n",
    "\n",
    "X_train = train_set_encoded.drop(columns=drop_cols, errors='ignore')\n",
    "y_train = train_set_encoded[\"price\"]\n",
    "\n",
    "X_val = val_set_encoded.drop(columns=drop_cols, errors='ignore')\n",
    "y_val = val_set_encoded[\"price\"]\n",
    "\n",
    "# C. Scaling (FIT on Train, TRANSFORM on both)\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns, index=X_train.index)\n",
    "X_val_scaled = pd.DataFrame(scaler.transform(X_val), columns=X_val.columns, index=X_val.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9aa262c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Combine processed data (Reset index to ensure alignment)\n",
    "X_combined = pd.concat([X_train_scaled, X_val_scaled], axis=0).reset_index(drop=True)\n",
    "y_combined = pd.concat([y_train, y_val], axis=0).reset_index(drop=True)\n",
    "\n",
    "# 2. Create the Split \"Mask\" (test_fold)\n",
    "# -1 indicates: \"This sample is for training, use it to learn\"\n",
    "#  0 indicates: \"This sample is for validation, use it to test\" (0 is the index of the validation fold)\n",
    "\n",
    "# Array with -1 for the length of the training set\n",
    "split_index_train = [-1] * len(X_train_scaled)\n",
    "# Array with 0 for the length of the validation set\n",
    "split_index_val = [0] * len(X_val_scaled)\n",
    "\n",
    "# Combine the two lists\n",
    "test_fold = split_index_train + split_index_val\n",
    "\n",
    "# 3. Create the PredefinedSplit Object\n",
    "ps = PredefinedSplit(test_fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa5dd3a",
   "metadata": {},
   "source": [
    "experimentar com fit.x_combined,y_combnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4687567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A treinar Regressão Linear Simples...\n",
      "RMSE Linear Simples (log): 0.1740\n"
     ]
    }
   ],
   "source": [
    "# 1. Filtrar os dados manualmente (já que não vamos usar o RandomizedSearch)\n",
    "# O ps.test_fold tem -1 (Treino) e 0 (Validação)\n",
    "X_train_lr = X_combined.iloc[[i for i, x in enumerate(ps.test_fold) if x == -1]]\n",
    "y_train_lr = y_combined.iloc[[i for i, x in enumerate(ps.test_fold) if x == -1]]\n",
    "\n",
    "X_val_lr = X_combined.iloc[[i for i, x in enumerate(ps.test_fold) if x == 0]]\n",
    "y_val_lr = y_combined.iloc[[i for i, x in enumerate(ps.test_fold) if x == 0]]\n",
    "\n",
    "# 2. Treinar\n",
    "lr_model = LinearRegression(n_jobs=-1)\n",
    "print(\"A treinar Regressão Linear Simples...\")\n",
    "lr_model.fit(X_train_lr, y_train_lr)\n",
    "\n",
    "# 3. Validar\n",
    "y_pred_log = lr_model.predict(X_val_lr)\n",
    "rmse_log = np.sqrt(mean_squared_error(y_val_lr, y_pred_log))\n",
    "\n",
    "print(f\"RMSE Linear Simples (log): {rmse_log:.4f}\")\n",
    "\n",
    "# Definir como o \"best_model\" para usares nos gráficos abaixo\n",
    "best_lr = lr_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3c868e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby(all_helpers, dropna=False, group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby(all_helpers, dropna=False, group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby(all_helpers, dropna=False, group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby(all_helpers, dropna=False, group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby(all_helpers, dropna=False, group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:107: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby('_combined_key', group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:107: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby('_combined_key', group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:107: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby('_combined_key', group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:107: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby('_combined_key', group_keys=False).apply(fill_group_cat, target_col)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions with Linear Regression model...\n",
      "Success! File 'submission_lr.csv' created.\n"
     ]
    }
   ],
   "source": [
    "# --- GENERATE SUBMISSION FOR LINEAR REGRESSION ---\n",
    "\n",
    "# 1. Load Test Data\n",
    "test_db = pd.read_csv(\"./test.csv\")\n",
    "\n",
    "# 2. Clean Data (Apply the exact same cleaning function used in training)\n",
    "test_clean = clean_data(test_db) \n",
    "\n",
    "# 3. ENCODING\n",
    "\n",
    "# A. One-Hot Encoding\n",
    "# We generate dummies first. Columns might differ from training, but we fix this in step 5.\n",
    "test_encoded = pd.get_dummies(test_clean, columns=[\"Brand\", \"transmission\", \"fuelType\"], drop_first=True)\n",
    "\n",
    "# B. Target Encoding\n",
    "# CRITICAL: Use the 'mapping' and 'global_mean' calculated on the TRAIN set.\n",
    "if 'mapping' in locals() and 'global_mean' in locals():\n",
    "    test_encoded[\"Brand_model_encoded\"] = test_clean.apply(\n",
    "        lambda x: mapping.get((x[\"Brand\"], x[\"model\"]), global_mean), axis=1\n",
    "    )\n",
    "else:\n",
    "    raise ValueError(\"Error: 'mapping' or 'global_mean' from training not found.\")\n",
    "\n",
    "# 4. FINAL PREPARATION\n",
    "# Remove the same columns dropped during training\n",
    "drop_cols = [\"price\", \"carID\", \"model\", \"previousOwners\"]\n",
    "X_test_lr = test_encoded.drop(columns=drop_cols, errors='ignore')\n",
    "\n",
    "# 5. COLUMN ALIGNMENT (Crucial for Linear Regression)\n",
    "# Linear Regression fails instantly if column order or number is different.\n",
    "# We force the test set to match X_combined (training structure) exactly.\n",
    "if 'X_combined' in locals():\n",
    "    train_cols = X_combined.columns\n",
    "    X_test_lr = X_test_lr.reindex(columns=train_cols, fill_value=0)\n",
    "else:\n",
    "    raise ValueError(\"Error: X_combined (training data) not found for alignment.\")\n",
    "\n",
    "# 6. SCALING\n",
    "# Use the scaler fitted on training data\n",
    "X_test_lr_scaled = pd.DataFrame(scaler.transform(X_test_lr), columns=X_test_lr.columns, index=X_test_lr.index)\n",
    "\n",
    "# 7. PREDICTION\n",
    "# Use 'best_lr' \n",
    "print(\"Making predictions with Linear Regression model...\")\n",
    "y_pred_lr_log = best_lr.predict(X_test_lr_scaled)\n",
    "\n",
    "# 8. INVERT LOG (Convert back to Euros)\n",
    "y_pred_lr_real = np.expm1(y_pred_lr_log)\n",
    "\n",
    "# 9. SAVE SUBMISSION\n",
    "submission_lr = pd.DataFrame({\n",
    "    \"carID\": test_db[\"carID\"],\n",
    "    \"price\": y_pred_lr_real\n",
    "})\n",
    "\n",
    "submission_lr.to_csv(\"submission_lr.csv\", index=False)\n",
    "print(\"Success! File 'submission_lr.csv' created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9084bd22",
   "metadata": {},
   "source": [
    "# KNN (K-Nearest Neighbors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e311ba",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning (K-Nearest Neighbors)\n",
    "\n",
    "We implement K-Nearest Neighbors (KNN), an instance-based learning algorithm that predicts the price of a car based on the average price of the 'k' most similar cars in the dataset.\n",
    "\n",
    "`Prerequisite (Scaling)`: KNN is distance-based, meaning it is highly sensitive to the scale of data. It is critical that we use X_combined (which uses MinMaxScaling), otherwise, features with large numbers (like mileage) would dominate features with small numbers (like year).\n",
    "\n",
    "`n_neighbors (k)`: We test values from 3 to 50. Low 'k' captures local details (but risks overfitting to noise), while high 'k' smooths the prediction (but risks underfitting).\n",
    "\n",
    "`weights`: We test 'distance' vs 'uniform'. In car pricing, 'distance' is usually superior because a car that is almost identical to the target should have more influence on the price than a car that is merely \"somewhat similar\".\n",
    "\n",
    "`metric`: We explore Manhattan (L1) and Euclidean (L2) distances. Manhattan distance often performs better in high-dimensional spaces created by One-Hot Encoding (sparse data)./6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892e2669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Definir o Modelo Base\n",
    "knn_model = KNeighborsRegressor(n_jobs=-1)\n",
    "\n",
    "# 2. Definir a Grelha de Hiperparâmetros\n",
    "param_dist_knn = {\n",
    "    # n_neighbors: 'K'. Valores baixos (3) ajustam muito, altos (50) generalizam.\n",
    "    'n_neighbors': randint(3, 50),\n",
    "    \n",
    "    # weights: \n",
    "    # 'uniform' = todos os vizinhos valem o mesmo.\n",
    "    # 'distance' = vizinhos mais próximos têm mais peso (geralmente melhor para preços)\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    \n",
    "    # metric: Como medir a distância entre os carros\n",
    "    # 'manhattan' (L1) costuma funcionar bem com muitas colunas (high-dim)\n",
    "    # 'euclidean' (L2) é o padrão geométrico\n",
    "    'metric': ['euclidean', 'manhattan', 'minkowski'],\n",
    "    \n",
    "    # p: Só é usado se metric='minkowski' (1=Manhattan, 2=Euclidean)\n",
    "    'p': [1, 2]\n",
    "}\n",
    "\n",
    "# 3. Configurar RandomizedSearchCV (Usando o MESMO 'ps' e 'X_combined')\n",
    "random_search_knn = RandomizedSearchCV(\n",
    "    estimator=knn_model,\n",
    "    param_distributions=param_dist_knn,\n",
    "    n_iter=50,     # KNN é muito rápido, podemos testar 30 combinações\n",
    "    cv=ps,         # Reutilizamos o PredefinedSplit criado no passo anterior\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 4. Executar a Busca\n",
    "print(\"A iniciar Random Search para KNN com Predefined Split...\")\n",
    "# IMPORTANTE: X_combined já está escalado (MinMaxScaler), o que é obrigatório para KNN!\n",
    "random_search_knn.fit(X_combined, y_combined)\n",
    "\n",
    "# 5. Resultados\n",
    "print(f\"Melhores Parâmetros KNN: {random_search_knn.best_params_}\")\n",
    "print(f\"Melhor RMSE KNN (log): {-random_search_knn.best_score_:.4f}\")\n",
    "\n",
    "# O melhor modelo KNN já fica treinado com TUDO\n",
    "best_knn = random_search_knn.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048ac6ee",
   "metadata": {},
   "source": [
    "### Prediction on Test Data \n",
    " We apply the exact same transformation pipeline to the unseen test.csv data to generate the final submission.\n",
    "\n",
    "- **Consistency**: We use the mapping (Target Encoding) and scaler learned from the training set. We do not refit them.\n",
    "\n",
    "- **Alignment**: We force the test dataset columns to match the training features exactly using reindex.\n",
    "\n",
    "- **Inference**: We predict the log-price using the optimized Decision Tree, apply np.expm1 to convert back to Euros, and save the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791cf6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- GERAR SUBMISSÃO PARA O KNN ---\n",
    "\n",
    "# 1. Carregar Teste\n",
    "test_db = pd.read_csv(\"./test.csv\")\n",
    "\n",
    "# 2. Limpeza (Usando a tua função clean_data)\n",
    "test_clean = clean_data(test_db)\n",
    "\n",
    "# 3. One-Hot Encoding (Alinhado)\n",
    "test_encoded = pd.get_dummies(test_clean, columns=[\"Brand\", \"transmission\", \"fuelType\"], drop_first=True)\n",
    "\n",
    "# 4. Target Encoding (Usar o 'mapping' do Treino!)\n",
    "test_encoded[\"Brand_model_encoded\"] = test_clean.apply(\n",
    "    lambda x: mapping.get((x[\"Brand\"], x[\"model\"]), global_mean), axis=1\n",
    ")\n",
    "\n",
    "# 5. Preparação Final (Remover colunas e Alinhar)\n",
    "drop_cols = [\"price\", \"carID\", \"model\", \"previousOwners\"]\n",
    "X_test_knn = test_encoded.drop(columns=drop_cols, errors='ignore')\n",
    "\n",
    "# ALINHAMENTO DE COLUNAS (Fundamental)\n",
    "# Garante que o teste tem as mesmas colunas que o X_combined\n",
    "cols_treino = X_combined.columns \n",
    "X_test_knn = X_test_knn.reindex(columns=cols_treino, fill_value=0)\n",
    "\n",
    "# 6. SCALING (Usar o scaler do treino)\n",
    "X_test_knn_scaled = pd.DataFrame(scaler.transform(X_test_knn), columns=X_test_knn.columns, index=X_test_knn.index)\n",
    "\n",
    "# 7. Previsão e Inversão do Log\n",
    "y_pred_knn_log = best_knn.predict(X_test_knn_scaled)\n",
    "y_pred_knn_real = np.expm1(y_pred_knn_log)\n",
    "\n",
    "# 8. Guardar\n",
    "submission_knn = pd.DataFrame({\n",
    "    \"carID\": test_db[\"carID\"],\n",
    "    \"price\": y_pred_knn_real\n",
    "})\n",
    "submission_knn.to_csv(\"submission_knn.csv\", index=False)\n",
    "print(\"Submissão KNN criada!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938b3691",
   "metadata": {},
   "source": [
    "# KNN Bagging (K-Nearest Neighbors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390f21e3",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning (KNN Bagging)\n",
    "\n",
    "We employ an advanced ensemble technique by wrapping K-Nearest Neighbors inside a Bagging Regressor.\n",
    "\n",
    "Rationale: Standard KNN can be sensitive to noisy outliers and irrelevant features (High Variance). By training multiple KNN models on random subsets of data, Bagging smoothes out these irregularities.\n",
    "\n",
    "`Nested Tuning (estimator__)`: We perform a \"Hybrid\" search. We tune the Macroscopic parameters (how many models, how much data they see via max_samples) simultaneously with the Microscopic parameters of the KNN itself (e.g., estimator__n_neighbors, distance metrics).\n",
    "\n",
    "`Feature Subsampling (max_features)`: Crucially, we test training each KNN on a random subset of columns. This forces the ensemble to learn from less dominant features, improving robustness against multicollinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddd1b23",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'KNeighborsRegressor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m knn_base = \u001b[43mKNeighborsRegressor\u001b[49m() \n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# 3. Definir o Bagging com KNN\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# O Bagging vai criar várias cópias deste knn_base\u001b[39;00m\n\u001b[32m      5\u001b[39m bagging_knn = BaggingRegressor(\n\u001b[32m      6\u001b[39m     estimator=knn_base,\n\u001b[32m      7\u001b[39m     random_state=\u001b[32m42\u001b[39m,\n\u001b[32m      8\u001b[39m     n_jobs=-\u001b[32m1\u001b[39m  \u001b[38;5;66;03m# Usa todos os processadores para treinar os modelos em paralelo\u001b[39;00m\n\u001b[32m      9\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'KNeighborsRegressor' is not defined"
     ]
    }
   ],
   "source": [
    "knn_base = KNeighborsRegressor() \n",
    "\n",
    "# 3. Definir o Bagging com KNN\n",
    "# O Bagging vai criar várias cópias deste knn_base\n",
    "bagging_knn = BaggingRegressor(\n",
    "    estimator=knn_base,\n",
    "    random_state=42,\n",
    "    n_jobs=-1  # Usa todos os processadores para treinar os modelos em paralelo\n",
    ")\n",
    "\n",
    "# 4. Grelha de Hiperparâmetros (Híbrida)\n",
    "# Aqui ajustamos o Bagging E o KNN ao mesmo tempo\n",
    "param_dist_bagging = {\n",
    "    # --- Parâmetros do BAGGING (O \"Chefe\") ---\n",
    "    # Quantos modelos KNN vamos criar? (10 a 100)\n",
    "    'n_estimators': [10, 30, 50, 100], \n",
    "    \n",
    "    # Quantas linhas (amostras) cada KNN vê? (0.5 = 50% dos dados, 1.0 = tudo)\n",
    "    # Reduzir isto aumenta a diversidade e reduz overfitting\n",
    "    'max_samples': [0.5, 0.7, 0.8, 1.0],\n",
    "    \n",
    "    # Quantas colunas (features) cada KNN vê? \n",
    "    # Ótimo para garantir que eles não olham todos para as mesmas coisas\n",
    "    'max_features': [0.7, 0.8, 0.9, 1.0],\n",
    "    \n",
    "    # --- Parâmetros do KNN Interno (O \"Trabalhador\") ---\n",
    "    # Atenção à sintaxe: \"estimator__nome_do_parametro\"\n",
    "    'estimator__n_neighbors': randint(3, 40),\n",
    "    'estimator__weights': ['distance', 'uniform'],\n",
    "    'estimator__metric': ['manhattan', 'euclidean'],\n",
    "    'estimator__p': [1, 2]\n",
    "}\n",
    "\n",
    "# 5. Randomized Search\n",
    "random_search_bagging = RandomizedSearchCV(\n",
    "    estimator=bagging_knn,\n",
    "    param_distributions=param_dist_bagging,\n",
    "    n_iter=30,      # CUIDADO: Bagging de KNN é pesado. 30 iterações podem demorar um pouco.\n",
    "    cv=ps,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    verbose=1,\n",
    "    n_jobs=-1,      # Processamento paralelo máximo\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 6. Executar\n",
    "print(\"A treinar Bagging com KNN... (Isto pode demorar uns minutos)\")\n",
    "random_search_bagging.fit(X_combined, y_combined)\n",
    "\n",
    "# 7. Resultados\n",
    "best_bagging_knn = random_search_bagging.best_estimator_\n",
    "\n",
    "print(f\"\\nMelhores Parâmetros: {random_search_bagging.best_params_}\")\n",
    "print(f\"Melhor RMSE Bagging-KNN (log): {-random_search_bagging.best_score_:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b30aa1a",
   "metadata": {},
   "source": [
    "### Prediction on Test Data \n",
    " We apply the exact same transformation pipeline to the unseen test.csv data to generate the final submission.\n",
    "\n",
    "- **Consistency**: We use the mapping (Target Encoding) and scaler learned from the training set. We do not refit them.\n",
    "\n",
    "- **Alignment**: We force the test dataset columns to match the training features exactly using reindex.\n",
    "\n",
    "- **Inference**: We predict the log-price using the optimized Decision Tree, apply np.expm1 to convert back to Euros, and save the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd743fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- GERAR SUBMISSÃO PARA O KNN ---\n",
    "\n",
    "# 1. Carregar Teste\n",
    "test_db = pd.read_csv(\"./test.csv\")\n",
    "\n",
    "# 2. Limpeza (Usando a tua função clean_data)\n",
    "test_clean = clean_data(test_db)\n",
    "\n",
    "# 3. One-Hot Encoding (Alinhado)\n",
    "test_encoded = pd.get_dummies(test_clean, columns=[\"Brand\", \"transmission\", \"fuelType\"], drop_first=True)\n",
    "\n",
    "# 4. Target Encoding (Usar o 'mapping' do Treino!)\n",
    "test_encoded[\"Brand_model_encoded\"] = test_clean.apply(\n",
    "    lambda x: mapping.get((x[\"Brand\"], x[\"model\"]), global_mean), axis=1\n",
    ")\n",
    "\n",
    "# 5. Preparação Final (Remover colunas e Alinhar)\n",
    "drop_cols = [\"price\", \"carID\", \"model\", \"previousOwners\"]\n",
    "X_test_knn = test_encoded.drop(columns=drop_cols, errors='ignore')\n",
    "\n",
    "# ALINHAMENTO DE COLUNAS (Fundamental)\n",
    "# Garante que o teste tem as mesmas colunas que o X_combined\n",
    "cols_treino = X_combined.columns \n",
    "X_test_knn = X_test_knn.reindex(columns=cols_treino, fill_value=0)\n",
    "\n",
    "# 6. SCALING (Usar o scaler do treino)\n",
    "X_test_knn_scaled = pd.DataFrame(scaler.transform(X_test_knn), columns=X_test_knn.columns, index=X_test_knn.index)\n",
    "\n",
    "# 7. Previsão e Inversão do Log\n",
    "y_pred_knn_log = best_bagging_knn.predict(X_test_knn_scaled)\n",
    "y_pred_knn_real = np.expm1(y_pred_knn_log)\n",
    "\n",
    "# 8. Guardar\n",
    "submission_knn = pd.DataFrame({\n",
    "    \"carID\": test_db[\"carID\"],\n",
    "    \"price\": y_pred_knn_real\n",
    "})\n",
    "submission_knn.to_csv(\"submission_knn.csv\", index=False)\n",
    "print(\"Submissão KNN criada!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e26e94c",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be4b034",
   "metadata": {},
   "source": [
    "### 1. Preprocessing Pipeline\n",
    "We optimize the Random Forest Regressor, an ensemble method that reduces overfitting by averaging hundreds of independent trees.\n",
    "\n",
    "`n_estimators` (500-3000): We test a large number of trees to ensure stability and maximize predictive power.\n",
    "\n",
    "`max_depth` (10-30+): Unlike single trees, Random Forests benefit from deeper trees. We test depths from 10 to None (unlimited) to capture complex non-linear patterns.\n",
    "\n",
    "`min_samples_leaf`: We tune this to force leaves to contain multiple samples, preventing the model from memorizing individual outlier cars.\n",
    "\n",
    "`Strategy`: We use RandomizedSearchCV with our PredefinedSplit, ensuring the tuning process respects our strict train/validation boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55bda3ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby(all_helpers, dropna=False, group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby(all_helpers, dropna=False, group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby(all_helpers, dropna=False, group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby(all_helpers, dropna=False, group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby(all_helpers, dropna=False, group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:107: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby('_combined_key', group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:107: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby('_combined_key', group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:107: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby('_combined_key', group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:107: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby('_combined_key', group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby(all_helpers, dropna=False, group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby(all_helpers, dropna=False, group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby(all_helpers, dropna=False, group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby(all_helpers, dropna=False, group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby(all_helpers, dropna=False, group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:107: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby('_combined_key', group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:107: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby('_combined_key', group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:107: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby('_combined_key', group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:107: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby('_combined_key', group_keys=False).apply(fill_group_cat, target_col)\n"
     ]
    }
   ],
   "source": [
    "# 1. Load Data\n",
    "train_db = pd.read_csv(\"./train.csv\")\n",
    "# Important: Apply log to the target right at the start (if that is the strategy)\n",
    "train_db['price'] = np.log1p(train_db['price'])\n",
    "\n",
    "# 2. HOLDOUT SPLIT (Initial Split)\n",
    "# Here we ensure that validation data never sees the training data\n",
    "train_set, val_set = train_test_split(train_db, test_size=0.3, random_state=42, shuffle=True)\n",
    "\n",
    "# 3. Independent Cleaning (Clean Data)\n",
    "train_set = clean_data(train_set)\n",
    "val_set = clean_data(val_set)\n",
    "\n",
    "# 4. ENCODING & SCALING (Where Data Leakage occurs if not careful)\n",
    "\n",
    "# A. One-Hot Encoding\n",
    "# We must ensure columns match. We concatenate just to generate dummies, then separate again.\n",
    "train_len = len(train_set)\n",
    "combined_temp = pd.concat([train_set, val_set], axis=0)\n",
    "\n",
    "combined_temp = pd.get_dummies(combined_temp, columns=[\"Brand\", \"transmission\", \"fuelType\"], drop_first=True)\n",
    "\n",
    "# Split back to Train and Validation\n",
    "train_set_encoded = combined_temp.iloc[:train_len].copy()\n",
    "val_set_encoded = combined_temp.iloc[train_len:].copy()\n",
    "\n",
    "# B. Target Encoding (FIT on Train, TRANSFORM on Train and Validation)\n",
    "# Calculate means on Train\n",
    "mapping = train_set.groupby([\"Brand\", \"model\"])[\"price\"].mean().to_dict()\n",
    "global_mean = train_set[\"price\"].mean()\n",
    "\n",
    "# Apply to Train\n",
    "train_set_encoded[\"Brand_model_encoded\"] = train_set.apply(\n",
    "    lambda x: mapping.get((x[\"Brand\"], x[\"model\"]), global_mean), axis=1\n",
    ")\n",
    "\n",
    "# Apply to Validation (using the training mapping!)\n",
    "val_set_encoded[\"Brand_model_encoded\"] = val_set.apply(\n",
    "    lambda x: mapping.get((x[\"Brand\"], x[\"model\"]), global_mean), axis=1\n",
    ")\n",
    "\n",
    "# 5. FINAL PREPARATION (X and y)\n",
    "drop_cols = [\"price\", \"carID\", \"model\", \"previousOwners\"] # Columns to remove\n",
    "\n",
    "X_train = train_set_encoded.drop(columns=drop_cols, errors='ignore')\n",
    "y_train = train_set_encoded[\"price\"]\n",
    "\n",
    "X_val = val_set_encoded.drop(columns=drop_cols, errors='ignore')\n",
    "y_val = val_set_encoded[\"price\"]\n",
    "\n",
    "# C. Scaling (FIT on Train, TRANSFORM on both)\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns, index=X_train.index)\n",
    "X_val_scaled = pd.DataFrame(scaler.transform(X_val), columns=X_val.columns, index=X_val.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f403b08a",
   "metadata": {},
   "source": [
    "### 2. Concatenation & Predefined Split \n",
    "To use RandomizedSearchCV with our specific holdout data, we concatenate the processed sets and create a PredefinedSplit. A mask (-1 for train, 0 for validation) forces the algorithm to validate strictly on our holdout set rather than using random cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a016a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Combine processed data (Reset index to ensure alignment)\n",
    "X_combined = pd.concat([X_train_scaled, X_val_scaled], axis=0).reset_index(drop=True)\n",
    "y_combined = pd.concat([y_train, y_val], axis=0).reset_index(drop=True)\n",
    "\n",
    "# 2. Create the Split \"Mask\" (test_fold)\n",
    "# -1 indicates: \"This sample is for training, use it to learn\"\n",
    "#  0 indicates: \"This sample is for validation, use it to test\" (0 is the index of the validation fold)\n",
    "\n",
    "# Array with -1 for the length of the training set\n",
    "split_index_train = [-1] * len(X_train_scaled)\n",
    "# Array with 0 for the length of the validation set\n",
    "split_index_val = [0] * len(X_val_scaled)\n",
    "\n",
    "# Combine the two lists\n",
    "test_fold = split_index_train + split_index_val\n",
    "\n",
    "# 3. Create the PredefinedSplit Object\n",
    "ps = PredefinedSplit(test_fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2365eec0",
   "metadata": {},
   "source": [
    "### 3. Randomized Search (Random Forest)\n",
    "We define the model and a hyperparameter grid. We then execute RandomizedSearchCV using our custom split (cv=ps), optimizing the model to minimize RMSE (Root Mean Squared Error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b4ab4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Random Search with Predefined Split...\n",
      "Fitting 1 folds for each of 50 candidates, totalling 50 fits\n"
     ]
    }
   ],
   "source": [
    "# 4. Configure RandomizedSearchCV with cv=ps\n",
    "# Example with Random Forest\n",
    "rf_model = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators': randint(500, 3000),\n",
    "    'max_depth': [None,10, 15, 20, 25, 30] , #pus 10 tbm\n",
    "    'min_samples_split': randint(2, 20),\n",
    "    'min_samples_leaf': randint(1, 10)\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf_model,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=50,        # Number of iterations\n",
    "    cv=ps,            # <--- HERE IS THE TRICK: We use our custom split\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 5. Execute the Search\n",
    "print(\"Starting Random Search with Predefined Split...\")\n",
    "# We pass X_combined and y_combined. It will handle the separation internally thanks to 'ps'.\n",
    "random_search.fit(X_combined, y_combined)\n",
    "\n",
    "# 6. Results\n",
    "print(f\"Best Parameters: {random_search.best_params_}\")\n",
    "print(f\"Best RMSE (log): {-random_search.best_score_:.4f}\")\n",
    "\n",
    "# The best model is already retrained on EVERYTHING (Train + Validation) if refit=True (default)\n",
    "best_model = random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84ec999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Recuperar o melhor modelo treinado\n",
    "best_model = random_search_gb.best_estimator_\n",
    "\n",
    "# 2. Fazer previsões\n",
    "y_train_pred = best_gb.predict(X_train_scaled)\n",
    "y_val_pred = best_gb.predict(X_val_scaled)\n",
    "\n",
    "# 3. Função auxiliar para calcular métricas\n",
    "def get_metrics(y_true, y_pred, dataset_name):\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    return {\n",
    "        \"Dataset\": dataset_name,\n",
    "        \"R2\": r2,\n",
    "        \"MAE\": mae,  # Já incluído aqui\n",
    "        \"RMSE\": rmse\n",
    "    }\n",
    "\n",
    "# 4. Calcular métricas na escala LOG\n",
    "metrics_train = get_metrics(y_train, y_train_pred, \"Treino (Log)\")\n",
    "metrics_val = get_metrics(y_val, y_val_pred, \"Validação (Log)\")\n",
    "\n",
    "# 5. Apresentar Tabela Comparativa\n",
    "df_metrics = pd.DataFrame([metrics_train, metrics_val])\n",
    "df_metrics.set_index(\"Dataset\", inplace=True)\n",
    "\n",
    "print(\"=== ANÁLISE DE OVERFITTING (Escala Logarítmica) ===\")\n",
    "print(df_metrics)\n",
    "\n",
    "# 6. Diagnóstico do Gap (Diferença)\n",
    "gap_rmse = metrics_val[\"RMSE\"] - metrics_train[\"RMSE\"]\n",
    "gap_mae = metrics_val[\"MAE\"] - metrics_train[\"MAE\"]  # <--- GAP MAE ADICIONADO\n",
    "gap_r2 = metrics_train[\"R2\"] - metrics_val[\"R2\"]\n",
    "\n",
    "print(\"\\n=== DIAGNÓSTICO DE OVERFITTING ===\")\n",
    "print(f\"Diferença RMSE (Val - Treino): {gap_rmse:.4f}\")\n",
    "print(f\"Diferença MAE  (Val - Treino): {gap_mae:.4f}\")\n",
    "print(f\"Queda no R2    (Treino - Val): {gap_r2:.4f}\")\n",
    "\n",
    "if gap_r2 > 0.10 or gap_rmse > 0.05:\n",
    "    print(\"⚠  ALERTA: Há sinais de Overfitting considerável.\")\n",
    "else:\n",
    "    print(\"✅  O modelo parece bem ajustado (Generalização sólida).\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 7. MÉTRICAS REAIS (EM EUROS)\n",
    "# ---------------------------------------------------------\n",
    "print(\"\\n=== MÉTRICAS REAIS (Euros - Aproximado) ===\")\n",
    "\n",
    "# Reverter o Log para valores reais\n",
    "y_train_real = np.expm1(y_train)\n",
    "y_val_real = np.expm1(y_val)\n",
    "y_train_pred_real = np.expm1(y_train_pred)\n",
    "y_val_pred_real = np.expm1(y_val_pred)\n",
    "\n",
    "# Cálculo do MAE e RMSE em Euros\n",
    "mae_real_train = mean_absolute_error(y_train_real, y_train_pred_real)\n",
    "mae_real_val = mean_absolute_error(y_val_real, y_val_pred_real)\n",
    "\n",
    "rmse_real_train = np.sqrt(mean_squared_error(y_train_real, y_train_pred_real))\n",
    "rmse_real_val = np.sqrt(mean_squared_error(y_val_real, y_val_pred_real))\n",
    "\n",
    "print(f\"Treino    -> MAE: € {mae_real_train:.2f}  | RMSE: € {rmse_real_train:.2f}\")\n",
    "print(f\"Validação -> MAE: € {mae_real_val:.2f}  | RMSE: € {rmse_real_val:.2f}\")\n",
    "\n",
    "print(\"-\" * 30)\n",
    "print(f\"O teu modelo erra, em média, € {mae_real_val:.2f} no conjunto de validação.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e098e3a",
   "metadata": {},
   "source": [
    "È preciso fazer isto? é a maneira correta? pq tou a ver apenas com o teste ou de validaçao sla, e pode dar overfit sla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f643d3c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A calcular previsões na validação...\n",
      "R² Score: 0.9753  (Ideal: 1.0)\n",
      "MAE:      902.49 €  (Erro médio em Euros)\n",
      "RMSE:     1515.79 €  (Erro penaliza outliers)\n"
     ]
    }
   ],
   "source": [
    "# --- MODEL EVALUATION ON VALIDATION SET ---\n",
    "\n",
    "# 1. Make Predictions\n",
    "# Ensure 'best_model' is the name of your trained model (or best_knn, best_rf, etc.)\n",
    "print(\"Calculating predictions on validation set...\")\n",
    "y_pred_val_log = best_model.predict(X_val_scaled)\n",
    "\n",
    "# 2. Invert Logarithm (Convert back to Euros)\n",
    "# Since you trained with np.log1p, you must use np.expm1 to revert\n",
    "y_pred_val_real = np.expm1(y_pred_val_log)\n",
    "y_val_real = np.expm1(y_val) # The original y_val was also in log scale\n",
    "\n",
    "# 3. Calculate Metrics\n",
    "r2 = r2_score(y_val_real, y_pred_val_real)\n",
    "mae = mean_absolute_error(y_val_real, y_pred_val_real)\n",
    "rmse = np.sqrt(mean_squared_error(y_val_real, y_pred_val_real))\n",
    "\n",
    "print(f\"R² Score: {r2:.4f}  (Ideal: 1.0)\")\n",
    "print(f\"MAE:      {mae:.2f} €  (Mean Error in Euros)\")\n",
    "print(f\"RMSE:     {rmse:.2f} €  (Error penalizes outliers)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7062e5",
   "metadata": {},
   "source": [
    "### 5. Prediction on Test Data \n",
    " We apply the exact same transformation pipeline to the unseen test.csv data to generate the final submission.\n",
    "\n",
    "- **Consistency**: We use the mapping (Target Encoding) and scaler learned from the training set. We do not refit them.\n",
    "\n",
    "- **Alignment**: We force the test dataset columns to match the training features exactly using reindex.\n",
    "\n",
    "- **Inference**: We predict the log-price using the optimized Decision Tree, apply np.expm1 to convert back to Euros, and save the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c754a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby(all_helpers, dropna=False, group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby(all_helpers, dropna=False, group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby(all_helpers, dropna=False, group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby(all_helpers, dropna=False, group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby(all_helpers, dropna=False, group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:107: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby('_combined_key', group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:107: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby('_combined_key', group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:107: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby('_combined_key', group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:107: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby('_combined_key', group_keys=False).apply(fill_group_cat, target_col)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making final predictions...\n",
      "Success! File 'submission_final_campeao.csv' created.\n"
     ]
    }
   ],
   "source": [
    "# 1. Load Test Data\n",
    "test_db = pd.read_csv(\"./test.csv\")\n",
    "\n",
    "# 2. Apply the same Cleaning (Function created previously)\n",
    "# Note: Ensure the 'clean_data' function was defined in the previous block\n",
    "test_db = clean_data(test_db) \n",
    "\n",
    "# 3. ENCODING (Maximum Caution here!)\n",
    "\n",
    "# A. One-Hot Encoding\n",
    "# get_dummies on the test set might generate different columns. We will resolve this in the alignment step.\n",
    "test_db_encoded = pd.get_dummies(test_db, columns=[\"Brand\", \"transmission\", \"fuelType\"], drop_first=True)\n",
    "\n",
    "# B. Target Encoding\n",
    "# IMPORTANT: Use the 'mapping' and 'global_mean' calculated on TRAIN (do not recalculate on test!)\n",
    "if 'mapping' not in locals() or 'global_mean' not in locals():\n",
    "    raise ValueError(\"Error: Train variables 'mapping' and 'global_mean' are not in memory.\")\n",
    "\n",
    "test_db_encoded[\"Brand_model_encoded\"] = test_db.apply(\n",
    "    lambda x: mapping.get((x[\"Brand\"], x[\"model\"]), global_mean), axis=1\n",
    ")\n",
    "\n",
    "# 4. FINAL PREPARATION\n",
    "# Remove the same columns we removed during training\n",
    "drop_cols = [\"price\", \"carID\", \"model\", \"previousOwners\"]\n",
    "X_test = test_db_encoded.drop(columns=drop_cols, errors='ignore')\n",
    "\n",
    "# 5. COLUMN ALIGNMENT (The \"Vaccine\" against errors)\n",
    "# The model was trained with X_combined. X_test must have exactly the same columns.\n",
    "# If any are missing (e.g., Ferrari), fill with 0. If there are extra ones, ignore them.\n",
    "train_cols = X_combined.columns # Columns used in the RandomizedSearch fit\n",
    "X_test = X_test.reindex(columns=train_cols, fill_value=0)\n",
    "\n",
    "# 6. SCALING\n",
    "# Use the already fitted 'scaler' (do not fit again!)\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns, index=X_test.index)\n",
    "\n",
    "# 7. PREDICTION\n",
    "# Use best_model (which is already trained on everything)\n",
    "print(\"Making final predictions...\")\n",
    "y_test_pred_log = best_model.predict(X_test_scaled)\n",
    "\n",
    "# 8. INVERT LOG (Convert back to Euros)\n",
    "y_test_pred_real = np.expm1(y_test_pred_log)\n",
    "\n",
    "# 9. SAVE SUBMISSION\n",
    "submission = pd.DataFrame({\n",
    "    \"carID\": test_db[\"carID\"], # Get original ID\n",
    "    \"price\": y_test_pred_real\n",
    "})\n",
    "\n",
    "submission.to_csv(\"submission_final_campeao.csv\", index=False)\n",
    "print(\"Success! File 'submission_final_campeao.csv' created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cb9c99",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289945fe",
   "metadata": {},
   "source": [
    "### 1. Hyperparameter Tuning (Decision Tree)\n",
    "\n",
    "Here, we optimize a single Decision Tree Regressor. Unlike Random Forests, a single tree is very prone to overfitting (memorizing the data). To prevent this, we tune specific regularization parameters:\n",
    "\n",
    "`ccp_alpha (Cost Complexity Pruning)`: The most critical parameter. It penalizes complex trees, cutting off branches that add little value.\n",
    "\n",
    "`max_depth` & `min_samples_leaf`: Structural constraints to ensure the tree remains generalizable.\n",
    "\n",
    "`criterion`: We test different error metrics (like 'squared_error' or 'absolute_error') to see which mathematical approach fits our data best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57bda50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Instanciar o modelo\n",
    "dt_model = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "# 2. Definir a grelha de parâmetros para o Random Search\n",
    "param_dist = {\n",
    "    # Critério de divisão: erro quadrático, absoluto, etc.\n",
    "    'criterion': ['squared_error', 'absolute_error', 'friedman_mse', 'poisson'],\n",
    "    \n",
    "    # Estratégia de divisão: 'best' (melhor split) ou 'random' (melhor split aleatório)\n",
    "    'splitter': ['best', 'random'],\n",
    "    \n",
    "    # Profundidade máxima da árvore (importante para evitar overfitting)\n",
    "    'max_depth': [None] + list(range(2, 21)),  # None ou entre 2 e 20\n",
    "    # Adiciona isto:\n",
    "    \n",
    "    'ccp_alpha': uniform(0.000, 0.02),  # Testa valores entre 0 e 0.02\n",
    "    \n",
    "    # Mínimo de amostras para dividir um nó\n",
    "    'min_samples_split': randint(2, 20),\n",
    "    \n",
    "    # Mínimo de amostras numa folha\n",
    "    'min_samples_leaf': randint(1, 20),\n",
    "    \n",
    "    # Número de features a considerar em cada split\n",
    "    'max_features': [None, 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# 3. Configurar o RandomizedSearchCV\n",
    "# n_iter=50: Vai testar 50 combinações diferentes\n",
    "# cv=5: Validação cruzada com 5 folds\n",
    "# scoring='r2': Vamos otimizar para o melhor R2\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=dt_model,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=50, \n",
    "    cv=ps,\n",
    "    scoring='r2', \n",
    "    n_jobs=-1,  # Usar todos os processadores\n",
    "    random_state=42,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"A iniciar o Random Search...\")\n",
    "random_search.fit(X_combined, y_combined)\n",
    "\n",
    "print(f\"Random Search concluído em {end_time - start_time:.2f} segundos.\")\n",
    "print(f\"Melhores parâmetros encontrados: {random_search.best_params_}\")\n",
    "print(f\"Melhor R2 (cross-validation): {random_search.best_score_:.4f}\")\n",
    "\n",
    "# Guardar o melhor modelo\n",
    "best_dt_model = random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bec3799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparar Baseline vs Tuned Model usando a função do professor\n",
    "df_compare = pd.DataFrame(columns=['Time','Train R2','Test R2'], index=['Baseline', 'Tuned DT'])\n",
    "show_results(df_compare, dt_default, best_dt_model)\n",
    "\n",
    "# Apresentar a tabela\n",
    "display(df_compare)\n",
    "\n",
    "# --- Avaliação Final no conjunto de Validação (X_val_num) ---\n",
    "print(\"\\n--- Avaliação no Conjunto de Validação ---\")\n",
    "# Previsões\n",
    "preds_val = best_dt_model.predict(X_val_scaled)\n",
    "\n",
    "# Métricas\n",
    "print(f\"R2 Score: {r2_score(y_val, preds_val):.4f}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_val, preds_val):.2f}\")\n",
    "print(f\"RMSE: {np.sqrt(mean_squared_error(y_val, preds_val)):.2f}\")\n",
    "\n",
    "# --- Visualização da Árvore (Opcional, se a profundidade permitir) ---\n",
    "# Se a árvore for muito profunda, o gráfico fica ilegível, por isso limitamos a visualização\n",
    "if best_dt_model.get_depth() < 5:\n",
    "    plt.figure(figsize=(20,10))\n",
    "    from sklearn import tree\n",
    "    tree.plot_tree(best_dt_model, \n",
    "                   feature_names=X_train_scaled.columns,\n",
    "                   filled=True, \n",
    "                   rounded=True, \n",
    "                   fontsize=10)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"\\nA árvore é muito profunda para visualizar completamente (Profundidade: {best_dt_model.get_depth()}).\")\n",
    "    print(\"Podes visualizar a importância das features:\")\n",
    "    \n",
    "    # Visualizar Importância das Features\n",
    "    importances = pd.Series(best_dt_model.feature_importances_, index=X_train_scaled.columns)\n",
    "    importances.sort_values(ascending=False).plot(kind='bar', figsize=(12,6))\n",
    "    plt.title(\"Importância das Features (Decision Tree)\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5729e14d",
   "metadata": {},
   "source": [
    "### 3. Prediction on Test Data \n",
    "We apply the exact same transformation pipeline to the unseen test.csv data to generate the final submission.\n",
    "\n",
    "- **Consistency**: We use the mapping (Target Encoding) and scaler learned from the training set. We do not refit them.\n",
    "\n",
    "- **Alignment**: We force the test dataset columns to match the training features exactly using reindex.\n",
    "\n",
    "- **Inference**: We predict the log-price using the optimized Decision Tree, apply np.expm1 to convert back to Euros, and save the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f502a207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Carregar Teste\n",
    "test_db = pd.read_csv(\"./test.csv\")\n",
    "\n",
    "# 2. Aplicar a mesma Limpeza (Função que criámos antes)\n",
    "# Nota: Garante que definiste a função 'clean_data' no bloco anterior\n",
    "test_db = clean_data(test_db) \n",
    "\n",
    "# 3. ENCODING (Cuidado Máximo aqui!)\n",
    "\n",
    "# A. One-Hot Encoding\n",
    "# O get_dummies no teste pode gerar colunas diferentes. Vamos resolver isso no passo de alinhamento.\n",
    "test_db_encoded = pd.get_dummies(test_db, columns=[\"Brand\", \"transmission\", \"fuelType\"], drop_first=True)\n",
    "\n",
    "# B. Target Encoding\n",
    "# IMPORTANTE: Usar o 'mapping' e 'global_mean' que calculaste no TREINO (não recalcules no teste!)\n",
    "if 'mapping' not in locals() or 'global_mean' not in locals():\n",
    "    raise ValueError(\"Erro: As variáveis 'mapping' e 'global_mean' do treino não estão na memória.\")\n",
    "\n",
    "test_db_encoded[\"Brand_model_encoded\"] = test_db.apply(\n",
    "    lambda x: mapping.get((x[\"Brand\"], x[\"model\"]), global_mean), axis=1\n",
    ")\n",
    "\n",
    "# 4. PREPARAÇÃO FINAL\n",
    "# Remover as mesmas colunas que removemos no treino\n",
    "drop_cols = [\"price\", \"carID\", \"model\", \"previousOwners\"]\n",
    "X_test = test_db_encoded.drop(columns=drop_cols, errors='ignore')\n",
    "\n",
    "# 5. ALINHAMENTO DE COLUNAS (A \"Vacina\" contra erros)\n",
    "# O modelo foi treinado com X_combined. O X_test tem de ter exatamente as mesmas colunas.\n",
    "# Se faltar alguma (ex: Ferrari), preenchemos com 0. Se houver a mais, ignoramos.\n",
    "cols_treino = X_combined.columns # Colunas usadas no fit do RandomizedSearch\n",
    "X_test = X_test.reindex(columns=cols_treino, fill_value=0)\n",
    "\n",
    "# 6. SCALING\n",
    "# Usar o 'scaler' já treinado (não fazer fit!)\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns, index=X_test.index)\n",
    "\n",
    "# 7. PREVISÃO\n",
    "# Usar o best_model (que já está treinado com tudo)\n",
    "print(\"A fazer previsões finais...\")\n",
    "y_test_pred_log = best_dt_model.predict(X_test_scaled)\n",
    "\n",
    "# 8. INVERTER O LOG (Trazer de volta para Euros)\n",
    "y_test_pred_real = np.expm1(y_test_pred_log)\n",
    "\n",
    "# 9. GUARDAR SUBMISSÃO\n",
    "submission = pd.DataFrame({\n",
    "    \"carID\": test_db[\"carID\"], # Buscar o ID original\n",
    "    \"price\": y_test_pred_real\n",
    "})\n",
    "\n",
    "submission.to_csv(\"submission_dt_camp.csv\", index=False)\n",
    "print(\"Sucesso! Ficheiro 'submission_dt_camp.csv' criado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1e52e7",
   "metadata": {},
   "source": [
    "# Decision Tree Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a5aae9",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning (Decision Tree Bagging)\n",
    "\n",
    "We implement Bagging (Bootstrap Aggregating) to upgrade a single Decision Tree into a robust ensemble. By averaging multiple trees trained on different subsets of data, we drastically reduce variance and overfitting.\n",
    "\n",
    "`max_samples` & `max_features`: These control the \"randomness.\" By forcing each tree to train on only a fraction of rows and columns, we ensure the trees are diverse (uncorrelated).\n",
    "\n",
    "`estimator__max_depth`: Unlike a single tree, we can allow bagged trees to be deeper (more complex). The ensemble process cancels out the individual noise they might learn.\n",
    "\n",
    "`n_estimators`: We combine 50 to 200 trees to stabilize the final prediction.\n",
    "\n",
    "`Strategy`: We use RandomizedSearchCV to simultaneously optimize the ensemble structure (Bagging params) and the internal tree structure (estimator__ params)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42da5303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Definir a Árvore Base (Sem restrições iniciais, a grelha vai tratar disso)\n",
    "tree_base = DecisionTreeRegressor(random_state=42) \n",
    "\n",
    "# 3. Definir o Bagging\n",
    "bagging_dt = BaggingRegressor(\n",
    "    estimator=tree_base,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# 4. Grelha de Hiperparâmetros (O Segredo)\n",
    "param_dist_dt = {\n",
    "    # --- Parâmetros do BAGGING ---\n",
    "    # n_estimators: Quantas árvores vamos criar?\n",
    "    'n_estimators': [50, 100, 200], \n",
    "    \n",
    "    # max_samples: Quantas linhas cada árvore vê? (0.7 = 70%)\n",
    "    # Reduzir isto cria árvores mais diferentes entre si (bom para reduzir variância)\n",
    "    'max_samples': [0.5, 0.7, 0.9, 1.0],\n",
    "    \n",
    "    # max_features: Quantas colunas cada árvore vê?\n",
    "    # Se for < 1.0, obriga as árvores a aprender caminhos diferentes.\n",
    "    'max_features': [0.5, 0.7, 0.9, 1.0],\n",
    "    \n",
    "    # --- Parâmetros da ÁRVORE (estimator__) ---\n",
    "    # max_depth: Profundidade da árvore. \n",
    "    # Árvores sozinhas fazem overfitting fácil, mas com Bagging podemos deixá-las crescer mais.\n",
    "    'estimator__max_depth': [None, 10, 20, 40],\n",
    "    \n",
    "    # min_samples_split: Mínimo para dividir um nó\n",
    "    'estimator__min_samples_split': randint(2, 20),\n",
    "    \n",
    "    # min_samples_leaf: Mínimo para ser uma folha\n",
    "    # Valores baixos (1-5) capturam detalhes, valores altos (10+) generalizam.\n",
    "    'estimator__min_samples_leaf': randint(1, 10)\n",
    "}\n",
    "\n",
    "# 5. Randomized Search\n",
    "random_search_dt = RandomizedSearchCV(\n",
    "    estimator=bagging_dt,\n",
    "    param_distributions=param_dist_dt,\n",
    "    n_iter=50,      # Decision Trees são rápidas, 50 iterações é tranquilo\n",
    "    cv=ps,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"A treinar Bagging com Decision Trees...\")\n",
    "random_search_dt.fit(X_combined, y_combined)\n",
    "\n",
    "# 6. Resultados\n",
    "best_bagging_dt = random_search_dt.best_estimator_\n",
    "\n",
    "print(f\"\\nMelhores Parâmetros: {random_search_dt.best_params_}\")\n",
    "print(f\"Melhor RMSE DT-Bagging (log): {-random_search_dt.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cab601c",
   "metadata": {},
   "source": [
    "### 5. Prediction on Test Data \n",
    " We apply the exact same transformation pipeline to the unseen test.csv data to generate the final submission.\n",
    "\n",
    "- **Consistency**: We use the mapping (Target Encoding) and scaler learned from the training set. We do not refit them.\n",
    "\n",
    "- **Alignment**: We force the test dataset columns to match the training features exactly using reindex.\n",
    "\n",
    "- **Inference**: We predict the log-price using the optimized Decision Tree, apply np.expm1 to convert back to Euros, and save the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1ba487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Carregar Teste\n",
    "test_db = pd.read_csv(\"./test.csv\")\n",
    "\n",
    "# 2. Pipeline de Limpeza (Certifique-se que clean_data, mapping, etc. estão na memória)\n",
    "test_db = clean_data(test_db) \n",
    "test_db_encoded = pd.get_dummies(test_db, columns=[\"Brand\", \"transmission\", \"fuelType\"], drop_first=True)\n",
    "\n",
    "test_db_encoded[\"Brand_model_encoded\"] = test_db.apply(\n",
    "    lambda x: mapping.get((x[\"Brand\"], x[\"model\"]), global_mean), axis=1\n",
    ")\n",
    "\n",
    "drop_cols = [\"price\", \"carID\", \"model\", \"previousOwners\"]\n",
    "X_test = test_db_encoded.drop(columns=drop_cols, errors='ignore')\n",
    "\n",
    "# Alinhamento\n",
    "cols_treino = X_combined.columns \n",
    "X_test = X_test.reindex(columns=cols_treino, fill_value=0)\n",
    "\n",
    "# Scaling\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns, index=X_test.index)\n",
    "\n",
    "# 3. PREVISÃO\n",
    "print(\"A fazer previsões finais com Decision Tree Bagging...\")\n",
    "y_test_pred_log = best_bagging_dt.predict(X_test_scaled)\n",
    "\n",
    "# 4. INVERTER O LOG\n",
    "y_test_pred_real = np.expm1(y_test_pred_log)\n",
    "\n",
    "# 5. GUARDAR\n",
    "submission = pd.DataFrame({\n",
    "    \"carID\": test_db[\"carID\"],\n",
    "    \"price\": y_test_pred_real\n",
    "})\n",
    "\n",
    "filename = \"submission_decision_tree_bagging.csv\"\n",
    "submission.to_csv(filename, index=False)\n",
    "print(f\"Sucesso! Ficheiro '{filename}' criado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370dd70f",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46db608a",
   "metadata": {},
   "source": [
    "### 4. Hyperparameter Tuning (Neural Network / MLP)\n",
    "\n",
    "We implement a Multi-Layer Perceptron (MLP) regressor to capture highly non-linear and complex relationships that tree-based models might miss.\n",
    "\n",
    "`Architecture (hidden_layer_sizes)`: We test various topologies, ranging from simple \"shallow\" networks (e.g., 1 hidden layer with 50 neurons) to \"deep\" architectures (e.g., 3 layers: 200-100-50) to find the optimal capacity.\n",
    "\n",
    "`Regularization (alpha)`: Crucial for Neural Networks. This L2 penalty prevents the model from assigning excessive weight to specific features, acting as a brake against overfitting.\n",
    "\n",
    "`activation` & `solver`: We explore how neurons process signals (standard relu vs. tanh) and the optimization algorithm used to update weights (adam for general purpose, sgd for fine-tuning).\n",
    "\n",
    "`Efficiency`: We utilize early_stopping to halt training immediately if the validation score stops improving, saving computational time and preventing the model from \"memorizing\" noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46dd71c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Definir o Modelo Base\n",
    "# max_iter=1000 dá tempo à rede para aprender sem parar cedo demais\n",
    "# early_stopping=True ajuda a parar se não estiver a aprender (poupa tempo)\n",
    "nn_model = MLPRegressor(max_iter=1000, early_stopping=True, random_state=42)\n",
    "\n",
    "# 2. Definir a Grelha de Hiperparâmetros\n",
    "param_dist = {\n",
    "    # Arquitetura: Testamos desde redes simples até muito profundas/largas\n",
    "    'hidden_layer_sizes': [\n",
    "        (50,), (100,), (100, 50), (200, 100), \n",
    "        (100, 50, 25), (200, 100, 50)  ###incluir sempre os defaults\n",
    "    ],\n",
    "    \n",
    "    # Ativação: A Tanh por vezes lida melhor com regressão do que a ReLU\n",
    "    'activation': ['relu', 'tanh', 'logistic'],\n",
    "    \n",
    "    # Solver: O SGD é clássico, Adam é moderno, LBFGS é bom para dados pequenos\n",
    "    'solver': ['adam', 'sgd', 'lbfgs'],\n",
    "    \n",
    "    # alpha: Regularização L2 (para evitar overfitting)\n",
    "    # Valores pequenos (0.0001) a moderados (0.05)\n",
    "    'alpha': [0.0001, 0.001, 0.01, 0.05],\n",
    "    \n",
    "    'batch_size': [32, 64, 'auto'],\n",
    "    # Learning Rate: Importante para o SGD\n",
    "    'learning_rate': ['constant', 'adaptive', 'invscaling'],\n",
    "    \n",
    "    \n",
    "    # Early Stopping: Ativar para evitar overfitting\n",
    "    'early_stopping': [True],\n",
    "    #como tenho early stopping \n",
    "    # Validation Fraction: Quanto dos dados de treino usar para parar cedo (se early_stopping=True)\n",
    "    'validation_fraction': [0.1, 0.2]\n",
    "}\n",
    "\n",
    "# 3. Randomized Search\n",
    "random_search_nn = RandomizedSearchCV(\n",
    "    estimator=nn_model,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=50,     # Testar 50 arquiteturas diferentes\n",
    "    cv=ps,         # O TEU SPLIT PERSONALIZADO\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 4. Executar a Busca\n",
    "print(\"A iniciar Random Search para Rede Neural...\")\n",
    "# IMPORTANTE: X_combined tem de estar ESCALADO!\n",
    "random_search_nn.fit(X_combined, y_combined)\n",
    "\n",
    "# 5. Resultados\n",
    "print(f\"Melhores Parâmetros NN: {random_search_nn.best_params_}\")\n",
    "print(f\"Melhor RMSE NN (log): {-random_search_nn.best_score_:.4f}\")\n",
    "\n",
    "# Guardar o campeão\n",
    "best_nn = random_search_nn.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ecce91",
   "metadata": {},
   "source": [
    "### 3. Prediction on Test Data \n",
    "We apply the exact same transformation pipeline to the unseen test.csv data to generate the final submission.\n",
    "\n",
    "- **Consistency**: We use the mapping (Target Encoding) and scaler learned from the training set. We do not refit them.\n",
    "\n",
    "- **Alignment**: We force the test dataset columns to match the training features exactly using reindex.\n",
    "\n",
    "- **Inference**: We predict the log-price using the optimized Decision Tree, apply np.expm1 to convert back to Euros, and save the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cb7f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- GERAR SUBMISSÃO PARA A REDE NEURAL ---\n",
    "\n",
    "# 1. Carregar Teste\n",
    "test_db = pd.read_csv(\"./test.csv\")\n",
    "\n",
    "# 3. Encoding\n",
    "test_encoded = pd.get_dummies(test_clean, columns=[\"Brand\", \"transmission\", \"fuelType\"], drop_first=True)\n",
    "\n",
    "# Target Encode\n",
    "test_encoded[\"Brand_model_encoded\"] = test_clean.apply(\n",
    "    lambda x: mapping.get((x[\"Brand\"], x[\"model\"]), global_mean), axis=1\n",
    ")\n",
    "\n",
    "# 4. Alinhamento de Colunas (Obrigatório)\n",
    "drop_cols = [\"price\", \"carID\", \"model\", \"previousOwners\"]\n",
    "X_test_nn = test_encoded.drop(columns=drop_cols, errors='ignore')\n",
    "\n",
    "# Garante que o teste tem as mesmas colunas que o treino\n",
    "cols_treino = X_combined.columns \n",
    "X_test_nn = X_test_nn.reindex(columns=cols_treino, fill_value=0)\n",
    "\n",
    "# 5. SCALING (Obrigatório: Usar o scaler do treino)\n",
    "X_test_nn_scaled = pd.DataFrame(scaler.transform(X_test_nn), columns=X_test_nn.columns, index=X_test_nn.index)\n",
    "\n",
    "# 6. Previsão\n",
    "print(\"A prever com a Rede Neural...\")\n",
    "y_pred_nn_log = best_nn.predict(X_test_nn_scaled)\n",
    "\n",
    "# Inverter Log\n",
    "y_pred_nn_real = np.expm1(y_pred_nn_log)\n",
    "\n",
    "# 7. Guardar\n",
    "submission_nn = pd.DataFrame({\n",
    "    \"carID\": test_db[\"carID\"],\n",
    "    \"price\": y_pred_nn_real\n",
    "})\n",
    "submission_nn.to_csv(\"submission_nn.csv\", index=False)\n",
    "print(\"Submissão Neural Network criada!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784e1194",
   "metadata": {},
   "source": [
    "# Gradient Boosting "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12e9e1e",
   "metadata": {},
   "source": [
    "o q reparo é que o melhor estimaters é 572, por isso n vale a pena aumentar mt o tamanho maximo de estimatores, e aumentar a depth é melhor (para 20 max)\n",
    "\n",
    "n aumentar o nº de iteraçoes n altera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81704441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A iniciar Random Search para Gradient Boosting...\n",
      "Fitting 1 folds for each of 30 candidates, totalling 30 fits\n",
      "Melhores Parâmetros GB: {'learning_rate': np.float64(0.05368808744336672), 'max_depth': 13, 'min_samples_leaf': 7, 'min_samples_split': 5, 'n_estimators': 572, 'subsample': np.float64(0.7954010424915591)}\n",
      "Melhor RMSE GB (log): 0.1124\n"
     ]
    }
   ],
   "source": [
    "# --- 1. CONFIGURAÇÃO DO MODELO ---\n",
    "# random_state garante reprodutibilidade\n",
    "# n_iter_no_change ajuda a parar se não estiver a melhorar (como o early stopping da NN)\n",
    "gb_model = GradientBoostingRegressor(random_state=42, validation_fraction=0.1, n_iter_no_change=10)\n",
    "\n",
    "# --- 2. GRELHA DE HIPERPARÂMETROS ---\n",
    "param_dist_gb = {\n",
    "    # Número de árvores (Boosters)\n",
    "    'n_estimators': randint(100, 1000),\n",
    "    \n",
    "    # Velocidade de aprendizagem (Crítico no GB!)\n",
    "    # Valores entre 0.01 e 0.2 costumam ser ideais\n",
    "    'learning_rate': uniform(0.01, 0.2),\n",
    "    \n",
    "    # Profundidade das árvores (MUITO IMPORTANTE: Manter baixo)\n",
    "    # GB usa \"weak learners\", árvores simples.\n",
    "    'max_depth': randint(3, 20),\n",
    "    \n",
    "    # Subsample: Treinar cada árvore com apenas X% dos dados (evita overfitting)\n",
    "    # Entre 0.7 e 1.0\n",
    "    'subsample': uniform(0.7, 0.3),\n",
    "    \n",
    "    # Mínimo de amostras para dividir\n",
    "    'min_samples_split': randint(2, 10),\n",
    "    'min_samples_leaf': randint(1, 10)\n",
    "}\n",
    "\n",
    "\n",
    "# --- 3. RANDOMIZED SEARCH ---\n",
    "random_search_gb = RandomizedSearchCV(\n",
    "    estimator=gb_model,\n",
    "    param_distributions=param_dist_gb,\n",
    "    n_iter=30,      # GB é mais lento que RF, 30 iterações é razoável\n",
    "    cv=ps,          # O teu PredefinedSplit\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# --- 4. TREINAR ---\n",
    "print(\"A iniciar Random Search para Gradient Boosting...\")\n",
    "# Usamos X_combined (que já tem One-Hot, Target Enc e está escalado)\n",
    "random_search_gb.fit(X_combined, y_combined)\n",
    "\n",
    "# --- 5. RESULTADOS ---\n",
    "print(f\"Melhores Parâmetros GB: {random_search_gb.best_params_}\")\n",
    "print(f\"Melhor RMSE GB (log): {-random_search_gb.best_score_:.4f}\")\n",
    "\n",
    "# Guardar o campeão\n",
    "best_gb = random_search_gb.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c03ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "     RELATÓRIO DE PERFORMANCE (GB)\n",
      "========================================\n",
      "R² Score: 0.9727  (Quanto mais perto de 1.0, melhor)\n",
      "RMSE:     1593.11 €  (Penaliza erros grandes/outliers)\n",
      "MAE:      970.40 €  (Erro médio absoluto)\n",
      "MAPE:     5.88%   (Erro percentual médio)\n",
      "========================================\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. Fazer Previsões (na Validação)\n",
    "y_pred_log = best_gb.predict(X_val_scaled) \n",
    "\n",
    "# 2. Inverter o Log (CRUCIAL!)\n",
    "y_pred_real = np.expm1(y_pred_log)\n",
    "y_val_real = np.expm1(y_val)\n",
    "\n",
    "# 3. Calcular Métricas\n",
    "rmse = np.sqrt(mean_squared_error(y_val_real, y_pred_real))\n",
    "mae = mean_absolute_error(y_val_real, y_pred_real)\n",
    "r2 = r2_score(y_val_real, y_pred_real)\n",
    "mape = mean_absolute_percentage_error(y_val_real, y_pred_real)\n",
    "\n",
    "# 4. Imprimir Relatório\n",
    "print(\"=\"*40)\n",
    "print(\"     RELATÓRIO DE PERFORMANCE (GB)\")\n",
    "print(\"=\"*40)\n",
    "print(f\"R² Score: {r2:.4f}  (Quanto mais perto de 1.0, melhor)\")\n",
    "print(f\"RMSE:     {rmse:.2f} €  (Penaliza erros grandes/outliers)\")\n",
    "print(f\"MAE:      {mae:.2f} €  (Erro médio absoluto)\")\n",
    "print(f\"MAPE:     {mape:.2%}   (Erro percentual médio)\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# 5. Análise Visual (Resíduos)\n",
    "# Se o modelo for bom, os pontos devem estar à volta da linha vermelha\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.scatterplot(x=y_val_real, y=y_pred_real, alpha=0.5)\n",
    "plt.plot([0, y_val_real.max()], [0, y_val_real.max()], color='red', linestyle='--', lw=2)\n",
    "plt.xlabel('Preço Real (€)')\n",
    "plt.ylabel('Preço Previsto (€)')\n",
    "plt.title('Real vs Previsto')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20985367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A calcular erro no Treino...\n",
      "A calcular erro na Validação...\n",
      "\n",
      "========================================\n",
      "     DIAGNÓSTICO DE OVERFITTING\n",
      "========================================\n",
      "RMSE Treino:     1718.04 €\n",
      "RMSE Validação:  1593.11 €\n",
      "----------------------------------------\n",
      "Diferença:       -124.93 €\n",
      "Piora na Validação: +-7.3%\n",
      "✅ SITUAÇÃO: Excelente (Generalização Robusta)\n"
     ]
    }
   ],
   "source": [
    "# 1. Prever no TREINO (O que o modelo já \"estudou\")\n",
    "# Usamos X_train_scaled (ou X_combined com filtro de treino se usaste PredefinedSplit)\n",
    "# Nota: Se usaste PredefinedSplit no X_combined, tens de filtrar o treino manualmente:\n",
    "indices_treino = [i for i, x in enumerate(ps.test_fold) if x == -1]\n",
    "X_train_check = X_combined.iloc[indices_treino]\n",
    "y_train_check = y_combined.iloc[indices_treino]\n",
    "\n",
    "print(\"A calcular erro no Treino...\")\n",
    "y_pred_train_log = best_gb.predict(X_train_check) # Usa o teu modelo (best_gb, best_rf, etc.)\n",
    "y_pred_train_real = np.expm1(y_pred_train_log)\n",
    "y_train_real = np.expm1(y_train_check)\n",
    "\n",
    "# 2. Prever na VALIDAÇÃO (O \"Exame\")\n",
    "indices_val = [i for i, x in enumerate(ps.test_fold) if x == 0]\n",
    "X_val_check = X_combined.iloc[indices_val]\n",
    "y_val_check = y_combined.iloc[indices_val]\n",
    "\n",
    "print(\"A calcular erro na Validação...\")\n",
    "y_pred_val_log = best_gb.predict(X_val_check)\n",
    "y_pred_val_real = np.expm1(y_pred_val_log)\n",
    "y_val_real = np.expm1(y_val_check)\n",
    "\n",
    "# 3. Calcular RMSE para ambos\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train_real, y_pred_train_real))\n",
    "rmse_val = np.sqrt(mean_squared_error(y_val_real, y_pred_val_real))\n",
    "\n",
    "# 4. O Veredicto\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"     DIAGNÓSTICO DE OVERFITTING\")\n",
    "print(\"=\"*40)\n",
    "print(f\"RMSE Treino:     {rmse_train:.2f} €\")\n",
    "print(f\"RMSE Validação:  {rmse_val:.2f} €\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "diferenca = rmse_val - rmse_train\n",
    "perc_pior = (diferenca / rmse_train) * 100\n",
    "\n",
    "print(f\"Diferença:       {diferenca:.2f} €\")\n",
    "print(f\"Piora na Validação: +{perc_pior:.1f}%\")\n",
    "\n",
    "if perc_pior < 10:\n",
    "    print(\"✅ SITUAÇÃO: Excelente (Generalização Robusta)\")\n",
    "elif perc_pior < 20:\n",
    "    print(\"⚠️ SITUAÇÃO: Normal (Ligeiro Overfitting, aceitável)\")\n",
    "else:\n",
    "    print(\"🚨 SITUAÇÃO: OVERFITTING GRAVE (O modelo decorou o treino!)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9dafd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby(all_helpers, dropna=False, group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby(all_helpers, dropna=False, group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby(all_helpers, dropna=False, group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby(all_helpers, dropna=False, group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby(all_helpers, dropna=False, group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:107: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby('_combined_key', group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:107: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby('_combined_key', group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:107: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby('_combined_key', group_keys=False).apply(fill_group_cat, target_col)\n",
      "c:\\Users\\Rodrigo\\Desktop\\escola\\4º Ano\\ML\\ProjetoML\\functionsML.py:107: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df.groupby('_combined_key', group_keys=False).apply(fill_group_cat, target_col)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A fazer previsões com Gradient Boosting...\n",
      "Submissão 'submission_gb.csv' criada com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# 1. Carregar\n",
    "test_db = pd.read_csv(\"./test.csv\")\n",
    "\n",
    "# 2. Limpeza (Usando a tua função atualizada com typos/logs/nulos)\n",
    "test_clean = clean_data(test_db) \n",
    "\n",
    "# 3. Encoding\n",
    "\n",
    "# A. One-Hot\n",
    "test_encoded = pd.get_dummies(test_clean, columns=[\"Brand\", \"transmission\", \"fuelType\"], drop_first=True)\n",
    "\n",
    "# B. Target Encoding (Usar mapping do Treino)\n",
    "if 'mapping' in locals():\n",
    "    test_encoded[\"Brand_model_encoded\"] = test_clean.apply(\n",
    "        lambda x: mapping.get((x[\"Brand\"], x[\"model\"]), global_mean), axis=1\n",
    "    )\n",
    "else:\n",
    "    print(\"ERRO: Mapping não encontrado. Corre o bloco de treino primeiro.\")\n",
    "\n",
    "# 4. Preparação e Alinhamento\n",
    "drop_cols = [\"price\", \"carID\", \"model\", \"previousOwners\"]\n",
    "X_test_gb = test_encoded.drop(columns=drop_cols, errors='ignore')\n",
    "\n",
    "# Alinhar colunas com o Treino (Fundamental)\n",
    "if 'X_combined' in locals():\n",
    "    cols_treino = X_combined.columns\n",
    "    X_test_gb = X_test_gb.reindex(columns=cols_treino, fill_value=0)\n",
    "else:\n",
    "    print(\"ERRO: X_combined não encontrado.\")\n",
    "\n",
    "# 5. Scaling (GB beneficia de scaling, embora não seja estritamente obrigatório como NN/KNN)\n",
    "# Vamos usar para manter consistência com o treino\n",
    "X_test_gb_scaled = pd.DataFrame(scaler.transform(X_test_gb), columns=X_test_gb.columns, index=X_test_gb.index)\n",
    "\n",
    "# 6. Previsão\n",
    "print(\"A fazer previsões com Gradient Boosting...\")\n",
    "y_pred_gb_log = best_gb.predict(X_test_gb_scaled)\n",
    "y_pred_gb_real = np.expm1(y_pred_gb_log)\n",
    "\n",
    "# 7. Guardar\n",
    "submission_gb = pd.DataFrame({\n",
    "    \"carID\": test_db[\"carID\"],\n",
    "    \"price\": y_pred_gb_real\n",
    "})\n",
    "\n",
    "submission_gb.to_csv(\"submission_gb.csv\", index=False)\n",
    "print(\"Submissão 'submission_gb.csv' criada com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b78dd9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
